{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Sprint24 Seq2Seq.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"1cGExp7cKuFv","colab_type":"text"},"source":["# Sprint24 Seq2Seq"]},{"cell_type":"markdown","metadata":{"id":"VPpqJTFuKuFw","colab_type":"text"},"source":["## 機械翻訳\n","\n","系列データに関する手法の基本的な活用例としては機械翻訳があります。これは系列データを入力し、系列データを出力する Sequence to Sequence の手法によって行えます。\n","\n","\n","## 【問題1】機械翻訳の実行とコードリーディング\n","Keras公式のサンプルコードで、短い英語からフランス語への変換を行うものが公開されています。これを動かしてください。\n","\n","\n","keras/lstm_seq2seq.py at master · keras-team/keras\n","\n","\n","その上でこのサンプルコードの各部分がどういった役割かを読み取り、まとめてください。以下のようにどこからどこの行が何をしているかを記述してください。\n","\n","\n","（例）\n","\n","\n","51から55行目 : ライブラリのimport\n","57から62行目 : ハイパーパラメータの設定\n","\n","《文字単位のトークン化》\n","\n","\n","この実装ではテキストのベクトル化の際に、単語ではなく文字ごとを1つのトークンとして扱っています。\n","\n","\n","scikit-learnでBoWを計算するCountVectorizerの場合では、デフォルトの引数はanalyzer=’word’で単語を扱いますが、charやchar_wbとすることで文字を扱えるようになります。\n","\n","charとchar_wbの2種類の方法があり、char_wbを指定した場合、n_gramが単語内からのみ作成されます。逆にcharは単語の区切りが関係なくn_gramが作成されます。This movie is very good.というテキストを3-gramでカウントする時、charではs mやe iといった単語をまたぐ数え方もしますが、char_wbではこれらを見ません。\n","\n","\n","sklearn.feature_extraction.text.CountVectorizer — scikit-learn 0.21.3 documentation"]},{"cell_type":"code","metadata":{"id":"axM0i6NFKuFw","colab_type":"code","colab":{},"outputId":"3c4e25b1-bc1f-4aab-c983-eb8772e05ebe"},"source":["from __future__ import print_function\n","\n","from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","import numpy as np\n","\n","batch_size = 64  # Batch size for training.\n","epochs = 5  # Number of epochs to train for.\n","latent_dim = 256  # Latent dimensionality of the encoding space.\n","num_samples = 10000  # Number of samples to train on.\n","# Path to the data txt file on disk.\n","data_path = 'fra-eng/fra.txt'\n","\n","# Vectorize the data.\n","input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    lines = f.read().split('\\n')\n","for line in lines[: min(num_samples, len(lines) - 1)]:\n","    input_text, target_text= line.split('\\t')\n","    # We use \"tab\" as the \"start sequence\" character\n","    # for the targets, and \"\\n\" as \"end sequence\" character.\n","    target_text = '\\t' + target_text + '\\n'\n","    input_texts.append(input_text)\n","    target_texts.append(target_text)\n","    for char in input_text:\n","        if char not in input_characters:\n","            input_characters.add(char)\n","    for char in target_text:\n","        if char not in target_characters:\n","            target_characters.add(char)\n","\n","input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","print('Number of samples:', len(input_texts))\n","print('Number of unique input tokens:', num_encoder_tokens)\n","print('Number of unique output tokens:', num_decoder_tokens)\n","print('Max sequence length for inputs:', max_encoder_seq_length)\n","print('Max sequence length for outputs:', max_decoder_seq_length)\n","\n","input_token_index = dict(\n","    [(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict(\n","    [(char, i) for i, char in enumerate(target_characters)])\n","\n","encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","\n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    for t, char in enumerate(input_text):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.\n","    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n","    for t, char in enumerate(target_text):\n","        # decoder_target_data is ahead of decoder_input_data by one timestep\n","        decoder_input_data[i, t, target_token_index[char]] = 1.\n","        if t > 0:\n","            # decoder_target_data will be ahead by one timestep\n","            # and will not include the start character.\n","            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n","    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n","    decoder_target_data[i, t:, target_token_index[' ']] = 1.\n","# Define an input sequence and process it.\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the\n","# return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n","                                     initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Run training\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_split=0.2)\n","# Save model\n","model.save('s2s.h5')\n","\n","# Next: inference mode (sampling).\n","# Here's the drill:\n","# 1) encode input and retrieve initial decoder state\n","# 2) run one step of decoder with this initial state\n","# and a \"start of sequence\" token as target.\n","# Output will be the next target token\n","# 3) Repeat with the current target token and current states\n","\n","# Define sampling models\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)\n","\n","# Reverse-lookup token index to decode sequences back to\n","# something readable.\n","reverse_input_char_index = dict(\n","    (i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict(\n","    (i, char) for char, i in target_token_index.items())\n","\n","\n","def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","        \n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence\n","\n","\n","for seq_index in range(100):\n","    # Take one sequence (part of the training set)\n","    # for trying out decoding.\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print('-')\n","    print('Input sentence:', input_texts[seq_index])\n","    print('Decoded sentence:', decoded_sentence)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of samples: 10000\n","Number of unique input tokens: 71\n","Number of unique output tokens: 91\n","Max sequence length for inputs: 16\n","Max sequence length for outputs: 59\n","WARNING:tensorflow:From /Users/mishibatoshihiro/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /Users/mishibatoshihiro/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /Users/mishibatoshihiro/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 8000 samples, validate on 2000 samples\n","Epoch 1/5\n","8000/8000 [==============================] - 91s 11ms/step - loss: 1.2029 - accuracy: 0.7189 - val_loss: 1.3251 - val_accuracy: 0.6748\n","Epoch 2/5\n","8000/8000 [==============================] - 85s 11ms/step - loss: 0.8760 - accuracy: 0.7646 - val_loss: 0.9085 - val_accuracy: 0.7514\n","Epoch 3/5\n","8000/8000 [==============================] - 83s 10ms/step - loss: 0.7170 - accuracy: 0.7995 - val_loss: 0.7795 - val_accuracy: 0.7763\n","Epoch 4/5\n","8000/8000 [==============================] - 83s 10ms/step - loss: 0.6190 - accuracy: 0.8201 - val_loss: 0.7145 - val_accuracy: 0.7912\n","Epoch 5/5\n","8000/8000 [==============================] - 82s 10ms/step - loss: 0.5640 - accuracy: 0.8348 - val_loss: 0.6716 - val_accuracy: 0.8027\n","-\n","Input sentence: Go.\n","Decoded sentence: Lais-le le terter.\n","\n","-\n","Input sentence: Run!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Run!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Wow!\n","Decoded sentence: Lais-le le terter.\n","\n","-\n","Input sentence: Fire!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Help!\n","Decoded sentence: Artez le menter.\n","\n","-\n","Input sentence: Jump.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Stop!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Stop!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Stop!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Wait!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Wait!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: I see.\n","Decoded sentence: Je suis pas pas de mait.\n","\n","-\n","Input sentence: I try.\n","Decoded sentence: Je me sent pas paste.\n","\n","-\n","Input sentence: I won!\n","Decoded sentence: Je suis pas pas de mait.\n","\n","-\n","Input sentence: I won!\n","Decoded sentence: Je suis pas pas de mait.\n","\n","-\n","Input sentence: Oh no!\n","Decoded sentence: C'est ent pas ?\n","\n","-\n","Input sentence: Attack!\n","Decoded sentence: Artez-le le terter.\n","\n","-\n","Input sentence: Attack!\n","Decoded sentence: Artez-le le terter.\n","\n","-\n","Input sentence: Cheers!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Cheers!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Cheers!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Get up.\n","Decoded sentence: Arrez le menter.\n","\n","-\n","Input sentence: Got it!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Got it!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Got it?\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Got it?\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Got it?\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Hop in.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Hop in.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Hug me.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Hug me.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: I fell.\n","Decoded sentence: Je suis enter.\n","\n","-\n","Input sentence: I fell.\n","Decoded sentence: Je suis enter.\n","\n","-\n","Input sentence: I know.\n","Decoded sentence: Je suis pas pas de mait.\n","\n","-\n","Input sentence: I left.\n","Decoded sentence: Je suis pas pas de mait.\n","\n","-\n","Input sentence: I left.\n","Decoded sentence: Je suis pas pas de mait.\n","\n","-\n","Input sentence: I lost.\n","Decoded sentence: Je me suis pas paste.\n","\n","-\n","Input sentence: I'm 19.\n","Decoded sentence: Je suis enter.\n","\n","-\n","Input sentence: I'm OK.\n","Decoded sentence: Je suis enter.\n","\n","-\n","Input sentence: I'm OK.\n","Decoded sentence: Je suis enter.\n","\n","-\n","Input sentence: Listen.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Really?\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Really?\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Really?\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Thanks.\n","Decoded sentence: C'est le lester.\n","\n","-\n","Input sentence: We try.\n","Decoded sentence: Nous sommes pas paster.\n","\n","-\n","Input sentence: We won.\n","Decoded sentence: Nous sommes pas paster.\n","\n","-\n","Input sentence: We won.\n","Decoded sentence: Nous sommes pas paster.\n","\n","-\n","Input sentence: We won.\n","Decoded sentence: Nous sommes pas paster.\n","\n","-\n","Input sentence: We won.\n","Decoded sentence: Nous sommes pas paster.\n","\n","-\n","Input sentence: Ask Tom.\n","Decoded sentence: Artez-le le terter.\n","\n","-\n","Input sentence: Awesome!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Be calm.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Be calm.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Be calm.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Be cool.\n","Decoded sentence: Sois ent mes !\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Be kind.\n","Decoded sentence: Arrez le menter.\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Lais-le mes !\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Lais-le mes !\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Lais-le mes !\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Lais-le mes !\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Lais-le mes !\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Lais-le mes !\n","\n","-\n","Input sentence: Beat it.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Call me.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Call me.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Call us.\n","Decoded sentence: Artez-le !\n","\n","-\n","Input sentence: Call us.\n","Decoded sentence: Artez-le !\n","\n","-\n","Input sentence: Come in.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Come in.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Come in.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Come in.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Come on!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Come on.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Come on.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Come on.\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Drop it!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Drop it!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Drop it!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Drop it!\n","Decoded sentence: Arrêtez le menter.\n","\n","-\n","Input sentence: Get out!\n","Decoded sentence: Sois ent pas !\n","\n","-\n","Input sentence: Get out!\n","Decoded sentence: Sois ent pas !\n","\n","-\n","Input sentence: Get out!\n","Decoded sentence: Sois ent pas !\n","\n","-\n","Input sentence: Get out.\n","Decoded sentence: Sois ent pas !\n","\n","-\n","Input sentence: Get out.\n","Decoded sentence: Sois ent pas !\n","\n","-\n","Input sentence: Go away!\n","Decoded sentence: Arrez le menter.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NCUaY2gAKuF0","colab_type":"text"},"source":["### コードリーディング\n","66から69行目：初期化\n","\n","70から84行目：ロードした文章の分割、単語化\n","\n","86から97行目：単語ソート、単語数と文章の最大長さの取得、表示\n","\n","99から102行目：単語の辞書化\n","\n","104から126行目：エンコーダーとデコーダーで使用するために文字化\n","\n","127から143行目：入力シーケンスを定義、エンコーダーとデコーダー設定（LSTM、Dense）\n","\n","145から157行目：学習、コンパイルと保存\n","\n","168から179行目：サンプリングモデルを定義\n","\n","183から186行目：シーケンスをデコードして戻す逆引きトークンインデックス\n","\n","189から224行目：デコード推論の関数\n","\n","227から234行目：推論結果の出力"]},{"cell_type":"markdown","metadata":{"id":"QXH4md6rKuF1","colab_type":"text"},"source":["## イメージキャプショニング\n","\n","他の活用例としてイメージキャプショニングがあります。画像に対する説明の文章を推定するタスクです。これは画像を入力し、系列データを出力する Image to Sequence の手法によって行えます。\n","\n","\n","pytorch-tutorial/tutorials/03-advanced/image_captioning at master · yunjey/pytorch-tutorial\n","\n","\n","イメージキャプショニングは学習に多くの時間がかかるため、ここでは学習済みの重みが公開されている実装を動かすことにします。Kerasには平易に扱える実装が公開されていないため、今回はPyTorchによる実装を扱います。\n","\n","\n","## 【問題2】イメージキャプショニングの学習済みモデルの実行\n","上記実装において 5. Test the model の項目を実行してください。また、自身で用意した画像に対しても文章を生成してください。これらに対してどういった文章が出力されたかを記録して提出してください。\n","\n","\n","データセットからの学習は行わず、学習済みの重みをダウンロードして利用します。\n","\n","\n","注意点として、デフォルトで設定されている重みのファイル名と、ダウンロードできる重みのファイル名は異なっています。ここは書き換える必要があります。"]},{"cell_type":"code","metadata":{"id":"yTl58QfMKuF1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594106834859,"user_tz":-540,"elapsed":20299,"user":{"displayName":"Toshihiro Mishiba","photoUrl":"","userId":"05871074394656223400"}},"outputId":"281e1fef-5d7f-494c-ddc5-3a9a413f38fa"},"source":["# 自分のマイドライブにマウントする\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IFrSN8FpLCt4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594106883888,"user_tz":-540,"elapsed":705,"user":{"displayName":"Toshihiro Mishiba","photoUrl":"","userId":"05871074394656223400"}},"outputId":"614c99e4-9f3b-4746-9f42-8b116ad99d5e"},"source":["cd drive/My Drive/Sprint24"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Sprint24\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LYySll7VLLk4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594106939784,"user_tz":-540,"elapsed":2440,"user":{"displayName":"Toshihiro Mishiba","photoUrl":"","userId":"05871074394656223400"}},"outputId":"eb8853e9-403d-4060-8175-b2758ec950fb"},"source":["import os\n","from PIL import Image\n","import numpy  as np\n","import tensorflow as tf\n","import keras\n","from tensorflow.keras import backend as K\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iDRR1BlXLYu1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1594107115384,"user_tz":-540,"elapsed":14276,"user":{"displayName":"Toshihiro Mishiba","photoUrl":"","userId":"05871074394656223400"}},"outputId":"ce7672ab-4e7e-41df-d3a6-48de82af9ba3"},"source":["# 1. Clone the repositories\n","!git clone https://github.com/pdollar/coco.git\n","!cd coco/PythonAPI/\n","!make\n","!python setup.py build\n","!python setup.py install\n","!cd ../../\n","!git clone https://github.com/yunjey/pytorch-tutorial.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'coco'...\n","remote: Enumerating objects: 975, done.\u001b[K\n","remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n","Receiving objects: 100% (975/975), 11.72 MiB | 13.40 MiB/s, done.\n","Resolving deltas: 100% (576/576), done.\n","make: *** No targets specified and no makefile found.  Stop.\n","python3: can't open file 'setup.py': [Errno 2] No such file or directory\n","python3: can't open file 'setup.py': [Errno 2] No such file or directory\n","Cloning into 'pytorch-tutorial'...\n","remote: Enumerating objects: 917, done.\u001b[K\n","remote: Total 917 (delta 0), reused 0 (delta 0), pack-reused 917\u001b[K\n","Receiving objects: 100% (917/917), 12.80 MiB | 16.03 MiB/s, done.\n","Resolving deltas: 100% (490/490), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5kOfjgLdNEtW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594107431812,"user_tz":-540,"elapsed":657,"user":{"displayName":"Toshihiro Mishiba","photoUrl":"","userId":"05871074394656223400"}},"outputId":"0f5f277d-3fd4-47da-8c78-210bf5e2e1ca"},"source":["# !cd pytorch-tutorial/tutorials/03-advanced/image_captioning/\n","os.chdir('./pytorch-tutorial/tutorials/03-advanced/image_captioning/')\n","# カレントディレクトリの取得\n","print(os.getcwd())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Sprint24/pytorch-tutorial/tutorials/03-advanced/image_captioning\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ynF55TXfMiK-","colab_type":"code","colab":{}},"source":["# # 2. Download the dataset\n","# !pip install -r requirements.txt\n","# !chmod +x download.sh\n","# !./download.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9t97CG-2Mm-s","colab_type":"code","colab":{}},"source":["# # 3. Preprocessing\n","# !python build_vocab.py   \n","# !python resize.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g_lIkEyfMnJt","colab_type":"code","colab":{}},"source":["# 4. Train the model\n","#python train.py   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N8Nu5gCvM3p0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594109150846,"user_tz":-540,"elapsed":12823,"user":{"displayName":"Toshihiro Mishiba","photoUrl":"","userId":"05871074394656223400"}},"outputId":"19a5cf78-9bcc-476e-abac-ba7d523297af"},"source":["# 5. Test the model\n","!python sample.py --image='png/example.png'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<start> a group of giraffes standing next to each other . <end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wgD8Xn0WM8ps","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594109523296,"user_tz":-540,"elapsed":8816,"user":{"displayName":"Toshihiro Mishiba","photoUrl":"","userId":"05871074394656223400"}},"outputId":"681b1532-58fd-438a-f919-9199324023d5"},"source":["# 自前の画像で確認\n","!python sample.py --image='png/Sprint24_sample.png'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<start> a small brown and white dog sitting on a couch . <end>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rubIyqDUKuF4","colab_type":"text"},"source":["### 【問題3】Kerasで動かしたい場合はどうするかを調査\n","PyTorchによる実装を動かしましたが、何らかの理由からKerasで動かしたい状況が考えられます。どういった手順を踏むことになるか調査し、できるだけ詳しく説明してください。\n","\n","\n","特に今回はPyTorchのための学習済みの重みをKerasで使えるようにしたいので、その点については必ず触れてください。"]},{"cell_type":"markdown","metadata":{"id":"shdLgF_LVeDS","colab_type":"text"},"source":["PyTorchの学習済み重みをONNX形式に変換して保存（torch.onnx.exportを使用）\n","\n","\n","ONNX形式をkerasで使用できる形式に変換（onnx2keras.onnx_to_kerasを使用）\n","\n","\n","チャネルファーストからチャネルラストに変換（PyTorchはチャネルファースト、onnx_to_keraのchange_ordering=True）\n","\n","\n","（layerによってはPyTorchからkeras形式に変換できない場合があるため、あらかじめ変換できるようにlayerを調整する）\n","\n","kerasで同様のエンコーダー、デコーダーなどをスクラッチする"]},{"cell_type":"markdown","metadata":{"id":"lH5HgXEfKuF7","colab_type":"text"},"source":["### 【問題4】（アドバンス課題）コードリーディングと書き換え\n","モデル部分はmodel.pyに書かれていますが、Kerasではこのモデルがどのように記述できるかを考え、コーディングしてください。その際機械翻訳のサンプルコードが参考になります。\n","\n"]},{"cell_type":"code","metadata":{"id":"IjTffRM2KuF7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7fSnfcaDKuF-","colab_type":"text"},"source":["## 【問題5】（アドバンス課題）発展的調査\n","《他の言語の翻訳を行う場合は？》\n","\n","\n","問題1の実装を使い日本語と英語の翻訳を行いたい場合はどのような手順を踏むか考えてみましょう。\n","\n","\n","《機械翻訳の発展的手法にはどのようなものがある？》\n","\n","\n","機械翻訳のための発展的手法にはどういったものがあるか調査してみましょう。\n","\n","\n","《文章から画像生成するには？》\n","\n","\n","イメージキャプショニングとは逆に文章から画像を生成する手法もあります。どういったものがあるか調査してみましょう。"]},{"cell_type":"markdown","metadata":{"id":"yZuE_884WhEW","colab_type":"text"},"source":[">Microsoft Researchが開発した“Drawing Bot”。\n","たとえば、「黄色の体と黒い羽を持ち、くちばしの短い鳥の写真」という文章を人間が絵に起こすとき、まず鳥の大まかな輪郭を描き、黄色のペンで塗りつぶし、黒いペンで翼を描き、短いくちばしを描くというプロセスを経て、人によっては、完成度を上げるために鳥の止まる木の枝も描く。ボットはそれと同様に画像を生成できるという。完成度を向上させるためには、文章に含まれていない詳細を描く必要があるため、「画像から説明文(キャプション)を生成する」よりも「キャプションから画像を生成する」ほうが難しい。研究チームのPengchuan Zhang氏は、そのために画像生成には、人工知能を実行している機械学習アルゴリズムが、画像の欠落部分を“想像”する必要があると説明している。Botのキモとなるのが「Generative Adversarial Network (GAN: 敵対的生成ネットワーク)」で、文章から画像を生成するジェネレータと、画像が文章に合っているかを判定するディスクリミネータの2つの機械学習モデルを組み合わせて、より高度な学習を行なう。"]}]}
