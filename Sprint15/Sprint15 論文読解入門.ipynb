{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprint15 論文読解入門\n",
    "\n",
    "以下の論文を読み問題に答えてください。CNNを使った物体検出（Object Detection）の代表的な研究です。\n",
    "\n",
    "\n",
    "[8]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015) 91–99\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/1506.01497.pdf\n",
    "\n",
    "### 問題\n",
    "それぞれについてJupyter Notebookにマークダウン形式で記述してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 物体検出の分野にはどういった手法が存在したか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "オブジェクト提案方法には、スーパーピクセルのグループ化に基づく方法（選択的検索[4]、CPMC [22]、MCG [23]など）やスライディングウィンドウに基づく方法（例：ウィンドウのオブジェクト性[24]、EdgeBoxes [ 6]）。オブジェクト提案手法は、検出器とは独立した外部モジュールとして採用されました（選択的検索[4]オブジェクト検出器、RCNN [5]、高速R-CNN [2]など）\n",
    "\n",
    "SPPnet [1]\n",
    "\n",
    "Fast R-CNN [2]\n",
    "\n",
    "今回の物は、2つのモジュールで構成されています。最初のモジュールは、領域を提案する深い完全たたみ込みネットワークで、2番目のモジュールは、提案された領域を使用するFast R-CNN検出器[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Fasterとあるが、どういった仕組みで高速化したのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最近注目されているニューラルネットワークの用語に「注意」メカニズムを使用して、RPNコンポーネントは統合ネットワークにどこを見るかを指示\n",
    "\n",
    "これまでは、選択的検索[4]で、設計された低レベル機能に基づいてスーパーピクセルを貪欲にマージするので時間かかった。（1桁遅かった）\n",
    "\n",
    "3 FASTER R-CNNから"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverFeatは、1ステージのクラス固有の検出パイプラインであり、今回の手法は、クラスにとらわれない提案とクラス固有の検出で構成される2ステージのカスケードです。OverFeatでは、領域ごとの機能は、スケールピラミッド上の1つのアスペクト比のスライディングウィンドウから取得されます。\n",
    "RPNでは、機能は正方形（3x3）のスライディングウィンドウからのものであり、異なるスケールとアスペクト比のアンカーに関連する提案を予測します。どちらの方法もスライディングウィンドウを使用しますが、領域提案タスクはFaster RCNNの最初の段階にすぎません。\n",
    "カスケードの第2ステージでは、地域ごとの機能が、地域の機能をより忠実にカバーする提案ボックスから適応的にプールされます[1]、[2]。\n",
    "これらの機能は、より正確な検出につながる\n",
    "\n",
    "論文場所：P10 左辺り\n",
    "\n",
    "One-Stage Detection vs. Two-Stage Proposal + Detection. The OverFeat paper [9] proposes a detection\n",
    "method that uses regressors and classifiers on sliding\n",
    "windows over convolutional feature maps. OverFeat\n",
    "is a one-stage, class-specific detection pipeline, and ours\n",
    "is a two-stage cascade consisting of class-agnostic proposals and class-specific detections. In OverFeat, the\n",
    "region-wise features come from a sliding window of\n",
    "one aspect ratio over a scale pyramid. These features\n",
    "are used to simultaneously determine the location and\n",
    "category of objects. In RPN, the features are from\n",
    "square (3×3) sliding windows and predict proposals\n",
    "relative to anchors with different scales and aspect\n",
    "ratios. Though both methods use sliding windows, the\n",
    "region proposal task is only the first stage of Faster RCNN—the downstream Fast R-CNN detector attends\n",
    "to the proposals to refine them. In the second stage of\n",
    "our cascade, the region-wise features are adaptively\n",
    "pooled [1], [2] from proposal boxes that more faithfully cover the features of the regions. We believe\n",
    "these features lead to more accurate detections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) RPNとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "検出ネットワークとフルイメージのたたみ込み機能を共有するリージョン提案ネットワーク（RPN）\n",
    "\n",
    "完全にたたみ込みネットワークであり、各位置でオブジェクトの境界とオブジェクトネススコアを同時に予測\n",
    "\n",
    "（任意のサイズの）画像を入力として受け取り、それぞれがオブジェクトネススコアを持つ一連の長方形のオブジェクト提案を出力\n",
    "\n",
    "エンドツーエンドでトレーニングされ、高速R-CNNが検出に使用する高品質の地域提案を生成\n",
    "\n",
    "Fast RCNNのような領域ベースの検出器で使用される畳み込み特徴マップは、領域提案の生成にも使用できることです。これらのたたみ込み機能に加えて、通常のグリッドの各位置で領域の境界とオブジェクトネススコアを同時に後退させるいくつかの追加のたたみ込み層を追加して、RPNを構築します。したがって、RPNは一種の完全たたみ込みネットワーク（FCN）[7]であり、特に検出提案を生成するタスクのためにエンドツーエンドでトレーニングできます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) RoIプーリングとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力を固定長に変換するアルゴリズムを適用し、入力特徴マップのサイズにかかわらず固定長の長さに変換する。\n",
    "\n",
    "領域検出された箇所に対し最大プーリングを行う。処理後のサイズは任意の大きさに決めることができる。\n",
    "\n",
    "例えば、領域検出された箇所が複数存在し大きさがバラバラであっても、指定したサイズに出力される。\n",
    "\n",
    "各領域が同じサイズになるため、どの領域も最後の全結合に通すことができる。\n",
    "\n",
    "\n",
    "[1]Spatial pyramid pooling in deep convolutional networks for visual recognition, 2.2 The Spatial Pyramid Pooling Layer、\n",
    "および [2]Fast R-CNN, 2.1. The RoI pooling layerから"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Anchorのサイズはどうするのが適切か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ボックス領域が1282、2562、および5122ピクセルの3つのスケールと、1：1、1：2、および2：1の3つのアスペクト比を使用\n",
    "各位置でアンカーを1つだけ使用する場合、mAPは3〜4％のかなりのマージンで低下します。 3スケール（1アスペクト比）または3アスペクト比（1スケール）を使用すると、mAPは高くなります。これは、回帰参照として複数のサイズのアンカーを使用することが効果的なソリューションであることを示しています。 1つのアスペクト比（69.8％）の3つのスケールを使用することは、このデータセットで3つのアスペクト比の3つのスケールを使用することと同じです。つまり、スケールとアスペクト比は、検出精度のために絡み合っていない次元ではありません。しかし、システムに柔軟性を持たせるために、これらの2つの次元を設計に採用しています。\n",
    "\n",
    "論文場所：P9 右上辺り\n",
    "\n",
    "If using just one anchor at each position, the mAP\n",
    "drops by a considerable margin of 3-4%. The mAP\n",
    "is higher if using 3 scales (with 1 aspect ratio) or 3\n",
    "aspect ratios (with 1 scale), demonstrating that using\n",
    "anchors of multiple sizes as the regression references\n",
    "is an effective solution. Using just 3 scales with 1\n",
    "aspect ratio (69.8%) is as good as using 3 scales with\n",
    "3 aspect ratios on this dataset, suggesting that scales\n",
    "and aspect ratios are not disentangled dimensions for\n",
    "the detection accuracy. But we still adopt these two\n",
    "dimensions in our designs to keep our system flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ：PASCAL VOC 2007検出ベンチマーク[11]、20のオブジェクトカテゴリにわたる約5kのtrainval画像と5kのテスト画像で構成、\n",
    "\n",
    "mageNetの事前トレーニング済みネットワークでは、5つの畳み込み層と3つの完全に接続された層を持つZFネット[32]の「高速」バージョンと、\n",
    "\n",
    "13の畳み込み層と3を持つパブリックVGG-16モデル7 [3]を使用\n",
    "\n",
    "指標値：検出平均の平均精度（mAP）\n",
    "\n",
    "論文場所：7P 左中央辺り\n",
    "\n",
    "4.1 Experiments on PASCAL VOC\n",
    "We comprehensively evaluate our method on the\n",
    "PASCAL VOC 2007 detection benchmark [11]. This\n",
    "dataset consists of about 5k trainval images and 5k\n",
    "test images over 20 object categories. We also provide\n",
    "results on the PASCAL VOC 2012 benchmark for a\n",
    "few models. For the ImageNet pre-trained network,\n",
    "we use the “fast” version of ZF net [32] that has\n",
    "5 convolutional layers and 3 fully-connected layers,\n",
    "and the public VGG-16 model7\n",
    "[3] that has 13 convolutional layers and 3 fully-connected layers. We\n",
    "primarily evaluate detection mean Average Precision\n",
    "(mAP), because this is the actual metric for object\n",
    "detection (rather than focusing on object proposal\n",
    "proxy metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (8) （アドバンス課題）Faster R-CNNよりも新しい物体検出の論文では、Faster R-CNNがどう引用されているか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
