{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint1 機械学習フロー\n",
    "### 【問題1】クロスバリデーション\n",
    "事前学習期間では検証データをはじめに分割しておき、それに対して指標値を計算することで検証を行っていました。（ホールドアウト法）しかし、分割の仕方により精度は変化します。実践的には クロスバリデーション（交差検証） を行います。分割を複数回行い、それぞれに対して学習と検証を行う方法です。複数回の分割のためにscikit-learnにはKFoldクラスが用意されています。\n",
    "\n",
    "\n",
    "事前学習期間の課題で作成したベースラインモデルに対してKFoldクラスによるクロスバリデーションを行うコードを作成し実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "train_data = pd.read_csv(\"application_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>APARTMENTS_AVG</th>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG</th>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <th>ELEVATORS_AVG</th>\n",
       "      <th>ENTRANCES_AVG</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <th>LIVINGAREA_AVG</th>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <th>NONLIVINGAREA_AVG</th>\n",
       "      <th>APARTMENTS_MODE</th>\n",
       "      <th>BASEMENTAREA_MODE</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <th>ELEVATORS_MODE</th>\n",
       "      <th>ENTRANCES_MODE</th>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <th>LIVINGAREA_MODE</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <th>NONLIVINGAREA_MODE</th>\n",
       "      <th>APARTMENTS_MEDI</th>\n",
       "      <th>BASEMENTAREA_MEDI</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI</th>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <th>ELEVATORS_MEDI</th>\n",
       "      <th>ENTRANCES_MEDI</th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>LIVINGAREA_MEDI</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>NONLIVINGAREA_MEDI</th>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>FLAG_DOCUMENT_2</th>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <th>FLAG_DOCUMENT_4</th>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <th>FLAG_DOCUMENT_6</th>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <th>FLAG_DOCUMENT_8</th>\n",
       "      <th>FLAG_DOCUMENT_9</th>\n",
       "      <th>FLAG_DOCUMENT_10</th>\n",
       "      <th>FLAG_DOCUMENT_11</th>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>-2120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>Stone, brick</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1134.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>Family</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>-291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>Block</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-828.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>-2531</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Government</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005</td>\n",
       "      <td>-3039</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>-2437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-617.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>-3458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Religion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307506</td>\n",
       "      <td>456251</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Separated</td>\n",
       "      <td>With parents</td>\n",
       "      <td>0.032561</td>\n",
       "      <td>-9327</td>\n",
       "      <td>-236</td>\n",
       "      <td>-8456.0</td>\n",
       "      <td>-1982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Services</td>\n",
       "      <td>0.145570</td>\n",
       "      <td>0.681632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>0.2001</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.2898</td>\n",
       "      <td>Stone, brick</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-273.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307507</td>\n",
       "      <td>456252</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>269550.0</td>\n",
       "      <td>12001.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Widow</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.025164</td>\n",
       "      <td>-20775</td>\n",
       "      <td>365243</td>\n",
       "      <td>-4388.0</td>\n",
       "      <td>-4090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XNA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.6406</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.6310</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>Stone, brick</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307508</td>\n",
       "      <td>456253</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>677664.0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Separated</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>-14966</td>\n",
       "      <td>-7921</td>\n",
       "      <td>-6737.0</td>\n",
       "      <td>-5150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Managers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>School</td>\n",
       "      <td>0.744026</td>\n",
       "      <td>0.535722</td>\n",
       "      <td>0.218859</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.0862</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7484</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7583</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.0862</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7518</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.9445</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.7970</td>\n",
       "      <td>Panel</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1909.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307509</td>\n",
       "      <td>456254</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>370107.0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>-11961</td>\n",
       "      <td>-4786</td>\n",
       "      <td>-2562.0</td>\n",
       "      <td>-931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Entity Type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514163</td>\n",
       "      <td>0.661024</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>Stone, brick</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-322.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307510</td>\n",
       "      <td>456255</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.046220</td>\n",
       "      <td>-16856</td>\n",
       "      <td>-1262</td>\n",
       "      <td>-5128.0</td>\n",
       "      <td>-410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.708569</td>\n",
       "      <td>0.113922</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>Panel</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-787.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0           100002       1         Cash loans           M            N   \n",
       "1           100003       0         Cash loans           F            N   \n",
       "2           100004       0    Revolving loans           M            Y   \n",
       "3           100006       0         Cash loans           F            N   \n",
       "4           100007       0         Cash loans           M            N   \n",
       "...            ...     ...                ...         ...          ...   \n",
       "307506      456251       0         Cash loans           M            N   \n",
       "307507      456252       0         Cash loans           F            N   \n",
       "307508      456253       0         Cash loans           F            N   \n",
       "307509      456254       1         Cash loans           F            N   \n",
       "307510      456255       0         Cash loans           F            N   \n",
       "\n",
       "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "0                    Y             0          202500.0    406597.5   \n",
       "1                    N             0          270000.0   1293502.5   \n",
       "2                    Y             0           67500.0    135000.0   \n",
       "3                    Y             0          135000.0    312682.5   \n",
       "4                    Y             0          121500.0    513000.0   \n",
       "...                ...           ...               ...         ...   \n",
       "307506               N             0          157500.0    254700.0   \n",
       "307507               Y             0           72000.0    269550.0   \n",
       "307508               Y             0          153000.0    677664.0   \n",
       "307509               Y             0          171000.0    370107.0   \n",
       "307510               N             0          157500.0    675000.0   \n",
       "\n",
       "        AMT_ANNUITY  AMT_GOODS_PRICE NAME_TYPE_SUITE      NAME_INCOME_TYPE  \\\n",
       "0           24700.5         351000.0   Unaccompanied               Working   \n",
       "1           35698.5        1129500.0          Family         State servant   \n",
       "2            6750.0         135000.0   Unaccompanied               Working   \n",
       "3           29686.5         297000.0   Unaccompanied               Working   \n",
       "4           21865.5         513000.0   Unaccompanied               Working   \n",
       "...             ...              ...             ...                   ...   \n",
       "307506      27558.0         225000.0   Unaccompanied               Working   \n",
       "307507      12001.5         225000.0   Unaccompanied             Pensioner   \n",
       "307508      29979.0         585000.0   Unaccompanied               Working   \n",
       "307509      20205.0         319500.0   Unaccompanied  Commercial associate   \n",
       "307510      49117.5         675000.0   Unaccompanied  Commercial associate   \n",
       "\n",
       "                  NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  \\\n",
       "0       Secondary / secondary special  Single / not married   \n",
       "1                    Higher education               Married   \n",
       "2       Secondary / secondary special  Single / not married   \n",
       "3       Secondary / secondary special        Civil marriage   \n",
       "4       Secondary / secondary special  Single / not married   \n",
       "...                               ...                   ...   \n",
       "307506  Secondary / secondary special             Separated   \n",
       "307507  Secondary / secondary special                 Widow   \n",
       "307508               Higher education             Separated   \n",
       "307509  Secondary / secondary special               Married   \n",
       "307510               Higher education               Married   \n",
       "\n",
       "        NAME_HOUSING_TYPE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "0       House / apartment                    0.018801       -9461   \n",
       "1       House / apartment                    0.003541      -16765   \n",
       "2       House / apartment                    0.010032      -19046   \n",
       "3       House / apartment                    0.008019      -19005   \n",
       "4       House / apartment                    0.028663      -19932   \n",
       "...                   ...                         ...         ...   \n",
       "307506       With parents                    0.032561       -9327   \n",
       "307507  House / apartment                    0.025164      -20775   \n",
       "307508  House / apartment                    0.005002      -14966   \n",
       "307509  House / apartment                    0.005313      -11961   \n",
       "307510  House / apartment                    0.046220      -16856   \n",
       "\n",
       "        DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  OWN_CAR_AGE  \\\n",
       "0                -637            -3648.0            -2120          NaN   \n",
       "1               -1188            -1186.0             -291          NaN   \n",
       "2                -225            -4260.0            -2531         26.0   \n",
       "3               -3039            -9833.0            -2437          NaN   \n",
       "4               -3038            -4311.0            -3458          NaN   \n",
       "...               ...                ...              ...          ...   \n",
       "307506           -236            -8456.0            -1982          NaN   \n",
       "307507         365243            -4388.0            -4090          NaN   \n",
       "307508          -7921            -6737.0            -5150          NaN   \n",
       "307509          -4786            -2562.0             -931          NaN   \n",
       "307510          -1262            -5128.0             -410          NaN   \n",
       "\n",
       "        FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  FLAG_CONT_MOBILE  \\\n",
       "0                1               1                0                 1   \n",
       "1                1               1                0                 1   \n",
       "2                1               1                1                 1   \n",
       "3                1               1                0                 1   \n",
       "4                1               1                0                 1   \n",
       "...            ...             ...              ...               ...   \n",
       "307506           1               1                0                 1   \n",
       "307507           1               0                0                 1   \n",
       "307508           1               1                0                 1   \n",
       "307509           1               1                0                 1   \n",
       "307510           1               1                1                 1   \n",
       "\n",
       "        FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  CNT_FAM_MEMBERS  \\\n",
       "0                1           0        Laborers              1.0   \n",
       "1                1           0      Core staff              2.0   \n",
       "2                1           0        Laborers              1.0   \n",
       "3                0           0        Laborers              2.0   \n",
       "4                0           0      Core staff              1.0   \n",
       "...            ...         ...             ...              ...   \n",
       "307506           0           0     Sales staff              1.0   \n",
       "307507           1           0             NaN              1.0   \n",
       "307508           0           1        Managers              1.0   \n",
       "307509           0           0        Laborers              2.0   \n",
       "307510           1           0        Laborers              2.0   \n",
       "\n",
       "        REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  \\\n",
       "0                          2                            2   \n",
       "1                          1                            1   \n",
       "2                          2                            2   \n",
       "3                          2                            2   \n",
       "4                          2                            2   \n",
       "...                      ...                          ...   \n",
       "307506                     1                            1   \n",
       "307507                     2                            2   \n",
       "307508                     3                            3   \n",
       "307509                     2                            2   \n",
       "307510                     1                            1   \n",
       "\n",
       "       WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  \\\n",
       "0                       WEDNESDAY                       10   \n",
       "1                          MONDAY                       11   \n",
       "2                          MONDAY                        9   \n",
       "3                       WEDNESDAY                       17   \n",
       "4                        THURSDAY                       11   \n",
       "...                           ...                      ...   \n",
       "307506                   THURSDAY                       15   \n",
       "307507                     MONDAY                        8   \n",
       "307508                   THURSDAY                        9   \n",
       "307509                  WEDNESDAY                        9   \n",
       "307510                   THURSDAY                       20   \n",
       "\n",
       "        REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  \\\n",
       "0                                0                           0   \n",
       "1                                0                           0   \n",
       "2                                0                           0   \n",
       "3                                0                           0   \n",
       "4                                0                           0   \n",
       "...                            ...                         ...   \n",
       "307506                           0                           0   \n",
       "307507                           0                           0   \n",
       "307508                           0                           0   \n",
       "307509                           0                           0   \n",
       "307510                           0                           0   \n",
       "\n",
       "        LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  \\\n",
       "0                                 0                       0   \n",
       "1                                 0                       0   \n",
       "2                                 0                       0   \n",
       "3                                 0                       0   \n",
       "4                                 0                       0   \n",
       "...                             ...                     ...   \n",
       "307506                            0                       0   \n",
       "307507                            0                       0   \n",
       "307508                            0                       0   \n",
       "307509                            0                       1   \n",
       "307510                            0                       0   \n",
       "\n",
       "        REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            1                        1   \n",
       "...                        ...                      ...   \n",
       "307506                       0                        0   \n",
       "307507                       0                        0   \n",
       "307508                       1                        1   \n",
       "307509                       1                        0   \n",
       "307510                       1                        1   \n",
       "\n",
       "             ORGANIZATION_TYPE  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  \\\n",
       "0       Business Entity Type 3      0.083037      0.262949      0.139376   \n",
       "1                       School      0.311267      0.622246           NaN   \n",
       "2                   Government           NaN      0.555912      0.729567   \n",
       "3       Business Entity Type 3           NaN      0.650442           NaN   \n",
       "4                     Religion           NaN      0.322738           NaN   \n",
       "...                        ...           ...           ...           ...   \n",
       "307506                Services      0.145570      0.681632           NaN   \n",
       "307507                     XNA           NaN      0.115992           NaN   \n",
       "307508                  School      0.744026      0.535722      0.218859   \n",
       "307509  Business Entity Type 1           NaN      0.514163      0.661024   \n",
       "307510  Business Entity Type 3      0.734460      0.708569      0.113922   \n",
       "\n",
       "        APARTMENTS_AVG  BASEMENTAREA_AVG  YEARS_BEGINEXPLUATATION_AVG  \\\n",
       "0               0.0247            0.0369                       0.9722   \n",
       "1               0.0959            0.0529                       0.9851   \n",
       "2                  NaN               NaN                          NaN   \n",
       "3                  NaN               NaN                          NaN   \n",
       "4                  NaN               NaN                          NaN   \n",
       "...                ...               ...                          ...   \n",
       "307506          0.2021            0.0887                       0.9876   \n",
       "307507          0.0247            0.0435                       0.9727   \n",
       "307508          0.1031            0.0862                       0.9816   \n",
       "307509          0.0124               NaN                       0.9771   \n",
       "307510          0.0742            0.0526                       0.9881   \n",
       "\n",
       "        YEARS_BUILD_AVG  COMMONAREA_AVG  ELEVATORS_AVG  ENTRANCES_AVG  \\\n",
       "0                0.6192          0.0143           0.00         0.0690   \n",
       "1                0.7960          0.0605           0.08         0.0345   \n",
       "2                   NaN             NaN            NaN            NaN   \n",
       "3                   NaN             NaN            NaN            NaN   \n",
       "4                   NaN             NaN            NaN            NaN   \n",
       "...                 ...             ...            ...            ...   \n",
       "307506           0.8300          0.0202           0.22         0.1034   \n",
       "307507           0.6260          0.0022           0.00         0.1034   \n",
       "307508           0.7484          0.0123           0.00         0.2069   \n",
       "307509              NaN             NaN            NaN         0.0690   \n",
       "307510              NaN          0.0176           0.08         0.0690   \n",
       "\n",
       "        FLOORSMAX_AVG  FLOORSMIN_AVG  LANDAREA_AVG  LIVINGAPARTMENTS_AVG  \\\n",
       "0              0.0833         0.1250        0.0369                0.0202   \n",
       "1              0.2917         0.3333        0.0130                0.0773   \n",
       "2                 NaN            NaN           NaN                   NaN   \n",
       "3                 NaN            NaN           NaN                   NaN   \n",
       "4                 NaN            NaN           NaN                   NaN   \n",
       "...               ...            ...           ...                   ...   \n",
       "307506         0.6042         0.2708        0.0594                0.1484   \n",
       "307507         0.0833         0.1250        0.0579                0.0202   \n",
       "307508         0.1667         0.2083           NaN                0.0841   \n",
       "307509         0.0417            NaN           NaN                   NaN   \n",
       "307510         0.3750            NaN           NaN                   NaN   \n",
       "\n",
       "        LIVINGAREA_AVG  NONLIVINGAPARTMENTS_AVG  NONLIVINGAREA_AVG  \\\n",
       "0               0.0190                   0.0000             0.0000   \n",
       "1               0.0549                   0.0039             0.0098   \n",
       "2                  NaN                      NaN                NaN   \n",
       "3                  NaN                      NaN                NaN   \n",
       "4                  NaN                      NaN                NaN   \n",
       "...                ...                      ...                ...   \n",
       "307506          0.1965                   0.0753             0.1095   \n",
       "307507          0.0257                   0.0000             0.0000   \n",
       "307508          0.9279                   0.0000             0.0000   \n",
       "307509          0.0061                      NaN                NaN   \n",
       "307510          0.0791                      NaN             0.0000   \n",
       "\n",
       "        APARTMENTS_MODE  BASEMENTAREA_MODE  YEARS_BEGINEXPLUATATION_MODE  \\\n",
       "0                0.0252             0.0383                        0.9722   \n",
       "1                0.0924             0.0538                        0.9851   \n",
       "2                   NaN                NaN                           NaN   \n",
       "3                   NaN                NaN                           NaN   \n",
       "4                   NaN                NaN                           NaN   \n",
       "...                 ...                ...                           ...   \n",
       "307506           0.1008             0.0172                        0.9782   \n",
       "307507           0.0252             0.0451                        0.9727   \n",
       "307508           0.1050             0.0894                        0.9816   \n",
       "307509           0.0126                NaN                        0.9772   \n",
       "307510           0.0756             0.0546                        0.9881   \n",
       "\n",
       "        YEARS_BUILD_MODE  COMMONAREA_MODE  ELEVATORS_MODE  ENTRANCES_MODE  \\\n",
       "0                 0.6341           0.0144          0.0000          0.0690   \n",
       "1                 0.8040           0.0497          0.0806          0.0345   \n",
       "2                    NaN              NaN             NaN             NaN   \n",
       "3                    NaN              NaN             NaN             NaN   \n",
       "4                    NaN              NaN             NaN             NaN   \n",
       "...                  ...              ...             ...             ...   \n",
       "307506            0.7125           0.0172          0.0806          0.0345   \n",
       "307507            0.6406           0.0022          0.0000          0.1034   \n",
       "307508            0.7583           0.0124          0.0000          0.2069   \n",
       "307509               NaN              NaN             NaN          0.0690   \n",
       "307510               NaN           0.0178          0.0806          0.0690   \n",
       "\n",
       "        FLOORSMAX_MODE  FLOORSMIN_MODE  LANDAREA_MODE  LIVINGAPARTMENTS_MODE  \\\n",
       "0               0.0833          0.1250         0.0377                 0.0220   \n",
       "1               0.2917          0.3333         0.0128                 0.0790   \n",
       "2                  NaN             NaN            NaN                    NaN   \n",
       "3                  NaN             NaN            NaN                    NaN   \n",
       "4                  NaN             NaN            NaN                    NaN   \n",
       "...                ...             ...            ...                    ...   \n",
       "307506          0.4583          0.0417         0.0094                 0.0882   \n",
       "307507          0.0833          0.1250         0.0592                 0.0220   \n",
       "307508          0.1667          0.2083            NaN                 0.0918   \n",
       "307509          0.0417             NaN            NaN                    NaN   \n",
       "307510          0.3750             NaN            NaN                    NaN   \n",
       "\n",
       "        LIVINGAREA_MODE  NONLIVINGAPARTMENTS_MODE  NONLIVINGAREA_MODE  \\\n",
       "0                0.0198                       0.0              0.0000   \n",
       "1                0.0554                       0.0              0.0000   \n",
       "2                   NaN                       NaN                 NaN   \n",
       "3                   NaN                       NaN                 NaN   \n",
       "4                   NaN                       NaN                 NaN   \n",
       "...                 ...                       ...                 ...   \n",
       "307506           0.0853                       0.0              0.0125   \n",
       "307507           0.0267                       0.0              0.0000   \n",
       "307508           0.9667                       0.0              0.0000   \n",
       "307509           0.0063                       NaN                 NaN   \n",
       "307510           0.0824                       NaN              0.0000   \n",
       "\n",
       "        APARTMENTS_MEDI  BASEMENTAREA_MEDI  YEARS_BEGINEXPLUATATION_MEDI  \\\n",
       "0                0.0250             0.0369                        0.9722   \n",
       "1                0.0968             0.0529                        0.9851   \n",
       "2                   NaN                NaN                           NaN   \n",
       "3                   NaN                NaN                           NaN   \n",
       "4                   NaN                NaN                           NaN   \n",
       "...                 ...                ...                           ...   \n",
       "307506           0.2040             0.0887                        0.9876   \n",
       "307507           0.0250             0.0435                        0.9727   \n",
       "307508           0.1041             0.0862                        0.9816   \n",
       "307509           0.0125                NaN                        0.9771   \n",
       "307510           0.0749             0.0526                        0.9881   \n",
       "\n",
       "        YEARS_BUILD_MEDI  COMMONAREA_MEDI  ELEVATORS_MEDI  ENTRANCES_MEDI  \\\n",
       "0                 0.6243           0.0144            0.00          0.0690   \n",
       "1                 0.7987           0.0608            0.08          0.0345   \n",
       "2                    NaN              NaN             NaN             NaN   \n",
       "3                    NaN              NaN             NaN             NaN   \n",
       "4                    NaN              NaN             NaN             NaN   \n",
       "...                  ...              ...             ...             ...   \n",
       "307506            0.8323           0.0203            0.22          0.1034   \n",
       "307507            0.6310           0.0022            0.00          0.1034   \n",
       "307508            0.7518           0.0124            0.00          0.2069   \n",
       "307509               NaN              NaN             NaN          0.0690   \n",
       "307510               NaN           0.0177            0.08          0.0690   \n",
       "\n",
       "        FLOORSMAX_MEDI  FLOORSMIN_MEDI  LANDAREA_MEDI  LIVINGAPARTMENTS_MEDI  \\\n",
       "0               0.0833          0.1250         0.0375                 0.0205   \n",
       "1               0.2917          0.3333         0.0132                 0.0787   \n",
       "2                  NaN             NaN            NaN                    NaN   \n",
       "3                  NaN             NaN            NaN                    NaN   \n",
       "4                  NaN             NaN            NaN                    NaN   \n",
       "...                ...             ...            ...                    ...   \n",
       "307506          0.6042          0.2708         0.0605                 0.1509   \n",
       "307507          0.0833          0.1250         0.0589                 0.0205   \n",
       "307508          0.1667          0.2083            NaN                 0.0855   \n",
       "307509          0.0417             NaN            NaN                    NaN   \n",
       "307510          0.3750             NaN            NaN                    NaN   \n",
       "\n",
       "        LIVINGAREA_MEDI  NONLIVINGAPARTMENTS_MEDI  NONLIVINGAREA_MEDI  \\\n",
       "0                0.0193                    0.0000              0.0000   \n",
       "1                0.0558                    0.0039              0.0100   \n",
       "2                   NaN                       NaN                 NaN   \n",
       "3                   NaN                       NaN                 NaN   \n",
       "4                   NaN                       NaN                 NaN   \n",
       "...                 ...                       ...                 ...   \n",
       "307506           0.2001                    0.0757              0.1118   \n",
       "307507           0.0261                    0.0000              0.0000   \n",
       "307508           0.9445                    0.0000              0.0000   \n",
       "307509           0.0062                       NaN                 NaN   \n",
       "307510           0.0805                       NaN              0.0000   \n",
       "\n",
       "       FONDKAPREMONT_MODE  HOUSETYPE_MODE  TOTALAREA_MODE WALLSMATERIAL_MODE  \\\n",
       "0        reg oper account  block of flats          0.0149       Stone, brick   \n",
       "1        reg oper account  block of flats          0.0714              Block   \n",
       "2                     NaN             NaN             NaN                NaN   \n",
       "3                     NaN             NaN             NaN                NaN   \n",
       "4                     NaN             NaN             NaN                NaN   \n",
       "...                   ...             ...             ...                ...   \n",
       "307506   reg oper account  block of flats          0.2898       Stone, brick   \n",
       "307507   reg oper account  block of flats          0.0214       Stone, brick   \n",
       "307508   reg oper account  block of flats          0.7970              Panel   \n",
       "307509                NaN  block of flats          0.0086       Stone, brick   \n",
       "307510                NaN  block of flats          0.0718              Panel   \n",
       "\n",
       "       EMERGENCYSTATE_MODE  OBS_30_CNT_SOCIAL_CIRCLE  \\\n",
       "0                       No                       2.0   \n",
       "1                       No                       1.0   \n",
       "2                      NaN                       0.0   \n",
       "3                      NaN                       2.0   \n",
       "4                      NaN                       0.0   \n",
       "...                    ...                       ...   \n",
       "307506                  No                       0.0   \n",
       "307507                  No                       0.0   \n",
       "307508                  No                       6.0   \n",
       "307509                  No                       0.0   \n",
       "307510                  No                       0.0   \n",
       "\n",
       "        DEF_30_CNT_SOCIAL_CIRCLE  OBS_60_CNT_SOCIAL_CIRCLE  \\\n",
       "0                            2.0                       2.0   \n",
       "1                            0.0                       1.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            0.0                       2.0   \n",
       "4                            0.0                       0.0   \n",
       "...                          ...                       ...   \n",
       "307506                       0.0                       0.0   \n",
       "307507                       0.0                       0.0   \n",
       "307508                       0.0                       6.0   \n",
       "307509                       0.0                       0.0   \n",
       "307510                       0.0                       0.0   \n",
       "\n",
       "        DEF_60_CNT_SOCIAL_CIRCLE  DAYS_LAST_PHONE_CHANGE  FLAG_DOCUMENT_2  \\\n",
       "0                            2.0                 -1134.0                0   \n",
       "1                            0.0                  -828.0                0   \n",
       "2                            0.0                  -815.0                0   \n",
       "3                            0.0                  -617.0                0   \n",
       "4                            0.0                 -1106.0                0   \n",
       "...                          ...                     ...              ...   \n",
       "307506                       0.0                  -273.0                0   \n",
       "307507                       0.0                     0.0                0   \n",
       "307508                       0.0                 -1909.0                0   \n",
       "307509                       0.0                  -322.0                0   \n",
       "307510                       0.0                  -787.0                0   \n",
       "\n",
       "        FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  FLAG_DOCUMENT_6  \\\n",
       "0                     1                0                0                0   \n",
       "1                     1                0                0                0   \n",
       "2                     0                0                0                0   \n",
       "3                     1                0                0                0   \n",
       "4                     0                0                0                0   \n",
       "...                 ...              ...              ...              ...   \n",
       "307506                0                0                0                0   \n",
       "307507                1                0                0                0   \n",
       "307508                1                0                0                0   \n",
       "307509                1                0                0                0   \n",
       "307510                1                0                0                0   \n",
       "\n",
       "        FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  FLAG_DOCUMENT_10  \\\n",
       "0                     0                0                0                 0   \n",
       "1                     0                0                0                 0   \n",
       "2                     0                0                0                 0   \n",
       "3                     0                0                0                 0   \n",
       "4                     0                1                0                 0   \n",
       "...                 ...              ...              ...               ...   \n",
       "307506                0                1                0                 0   \n",
       "307507                0                0                0                 0   \n",
       "307508                0                0                0                 0   \n",
       "307509                0                0                0                 0   \n",
       "307510                0                0                0                 0   \n",
       "\n",
       "        FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  \\\n",
       "0                      0                 0                 0   \n",
       "1                      0                 0                 0   \n",
       "2                      0                 0                 0   \n",
       "3                      0                 0                 0   \n",
       "4                      0                 0                 0   \n",
       "...                  ...               ...               ...   \n",
       "307506                 0                 0                 0   \n",
       "307507                 0                 0                 0   \n",
       "307508                 0                 0                 0   \n",
       "307509                 0                 0                 0   \n",
       "307510                 0                 0                 0   \n",
       "\n",
       "        FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  \\\n",
       "0                      0                 0                 0   \n",
       "1                      0                 0                 0   \n",
       "2                      0                 0                 0   \n",
       "3                      0                 0                 0   \n",
       "4                      0                 0                 0   \n",
       "...                  ...               ...               ...   \n",
       "307506                 0                 0                 0   \n",
       "307507                 0                 0                 0   \n",
       "307508                 0                 0                 0   \n",
       "307509                 0                 0                 0   \n",
       "307510                 0                 0                 0   \n",
       "\n",
       "        FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  \\\n",
       "0                      0                 0                 0   \n",
       "1                      0                 0                 0   \n",
       "2                      0                 0                 0   \n",
       "3                      0                 0                 0   \n",
       "4                      0                 0                 0   \n",
       "...                  ...               ...               ...   \n",
       "307506                 0                 0                 0   \n",
       "307507                 0                 0                 0   \n",
       "307508                 0                 0                 0   \n",
       "307509                 0                 0                 0   \n",
       "307510                 0                 0                 0   \n",
       "\n",
       "        FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                      0                 0                         0.0   \n",
       "1                      0                 0                         0.0   \n",
       "2                      0                 0                         0.0   \n",
       "3                      0                 0                         NaN   \n",
       "4                      0                 0                         0.0   \n",
       "...                  ...               ...                         ...   \n",
       "307506                 0                 0                         NaN   \n",
       "307507                 0                 0                         NaN   \n",
       "307508                 0                 0                         1.0   \n",
       "307509                 0                 0                         0.0   \n",
       "307510                 0                 0                         0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0                             0.0                         0.0   \n",
       "1                             0.0                         0.0   \n",
       "2                             0.0                         0.0   \n",
       "3                             NaN                         NaN   \n",
       "4                             0.0                         0.0   \n",
       "...                           ...                         ...   \n",
       "307506                        NaN                         NaN   \n",
       "307507                        NaN                         NaN   \n",
       "307508                        0.0                         0.0   \n",
       "307509                        0.0                         0.0   \n",
       "307510                        0.0                         0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                             0.0                        0.0   \n",
       "1                             0.0                        0.0   \n",
       "2                             0.0                        0.0   \n",
       "3                             NaN                        NaN   \n",
       "4                             0.0                        0.0   \n",
       "...                           ...                        ...   \n",
       "307506                        NaN                        NaN   \n",
       "307507                        NaN                        NaN   \n",
       "307508                        1.0                        0.0   \n",
       "307509                        0.0                        0.0   \n",
       "307510                        2.0                        0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                              1.0  \n",
       "1                              0.0  \n",
       "2                              0.0  \n",
       "3                              NaN  \n",
       "4                              0.0  \n",
       "...                            ...  \n",
       "307506                         NaN  \n",
       "307507                         NaN  \n",
       "307508                         1.0  \n",
       "307509                         0.0  \n",
       "307510                         1.0  \n",
       "\n",
       "[307511 rows x 122 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ取得\n",
    "pd.set_option('display.max_columns', 122)\n",
    "pd.set_option('display.max_rows', 122)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-9461</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-13778</td>\n",
       "      <td>0.774761</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.492060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-20099</td>\n",
       "      <td>0.587334</td>\n",
       "      <td>0.205747</td>\n",
       "      <td>0.751724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-10197</td>\n",
       "      <td>0.319760</td>\n",
       "      <td>0.651862</td>\n",
       "      <td>0.363945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>-20417</td>\n",
       "      <td>0.722044</td>\n",
       "      <td>0.555183</td>\n",
       "      <td>0.652897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307499</td>\n",
       "      <td>-16988</td>\n",
       "      <td>0.665343</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.206779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307500</td>\n",
       "      <td>-20390</td>\n",
       "      <td>0.896042</td>\n",
       "      <td>0.789389</td>\n",
       "      <td>0.337673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307503</td>\n",
       "      <td>-11870</td>\n",
       "      <td>0.243466</td>\n",
       "      <td>0.501221</td>\n",
       "      <td>0.609276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307508</td>\n",
       "      <td>-14966</td>\n",
       "      <td>0.744026</td>\n",
       "      <td>0.535722</td>\n",
       "      <td>0.218859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307510</td>\n",
       "      <td>-16856</td>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.708569</td>\n",
       "      <td>0.113922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109589 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DAYS_BIRTH  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3\n",
       "0            -9461      0.083037      0.262949      0.139376\n",
       "6           -13778      0.774761      0.724000      0.492060\n",
       "8           -20099      0.587334      0.205747      0.751724\n",
       "10          -10197      0.319760      0.651862      0.363945\n",
       "11          -20417      0.722044      0.555183      0.652897\n",
       "...            ...           ...           ...           ...\n",
       "307499      -16988      0.665343      0.649123      0.206779\n",
       "307500      -20390      0.896042      0.789389      0.337673\n",
       "307503      -11870      0.243466      0.501221      0.609276\n",
       "307508      -14966      0.744026      0.535722      0.218859\n",
       "307510      -16856      0.734460      0.708569      0.113922\n",
       "\n",
       "[109589 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用する特徴量とターゲットを抽出する\n",
    "train_data = train_data[[\"DAYS_BIRTH\",\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\",\"TARGET\"]]\n",
    "train_data = train_data.dropna(how=\"any\")\n",
    "train_data[[\"DAYS_BIRTH\",\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DAYS_BIRTH  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3\n",
      "0            -9461      0.083037      0.262949      0.139376\n",
      "6           -13778      0.774761      0.724000      0.492060\n",
      "8           -20099      0.587334      0.205747      0.751724\n",
      "10          -10197      0.319760      0.651862      0.363945\n",
      "11          -20417      0.722044      0.555183      0.652897\n",
      "...            ...           ...           ...           ...\n",
      "307499      -16988      0.665343      0.649123      0.206779\n",
      "307500      -20390      0.896042      0.789389      0.337673\n",
      "307503      -11870      0.243466      0.501221      0.609276\n",
      "307508      -14966      0.744026      0.535722      0.218859\n",
      "307510      -16856      0.734460      0.708569      0.113922\n",
      "\n",
      "[109589 rows x 4 columns]\n",
      "0         1\n",
      "6         0\n",
      "8         0\n",
      "10        0\n",
      "11        0\n",
      "         ..\n",
      "307499    0\n",
      "307500    0\n",
      "307503    0\n",
      "307508    0\n",
      "307510    0\n",
      "Name: TARGET, Length: 109589, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7998"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欠損値は削除しX、yに代入\n",
    "\n",
    "train_data = train_data[[\"DAYS_BIRTH\",\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\",\"TARGET\"]]\n",
    "train_data = train_data.dropna(how=\"any\")\n",
    "\n",
    "X = train_data[[\"DAYS_BIRTH\",\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]]\n",
    "print(X)\n",
    "y = train_data[\"TARGET\"]\n",
    "print(y)\n",
    "sum(y==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6933924423182928, 0.6798055260256712, 0.6805350170951292, 0.6893350305502793]\n",
      "0.6857670039973431\n"
     ]
    }
   ],
   "source": [
    "# クロスバリデーションを実施。　右記でも可能。cross_validate(clf, X, y, cv=skf, scoring=score_funcs)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4,random_state=1)\n",
    "score_probs = []\n",
    "\n",
    "for tr_idx, va_idx in kf.split(X,y):\n",
    "    # 学習データとバリデーションに分ける\n",
    "    tr_X, va_X = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    \n",
    "    # 標準化\n",
    "    sscaler = StandardScaler()\n",
    "    sscaler.fit(tr_X)\n",
    "    tr_X_scalered = sscaler.transform(tr_X)\n",
    "    va_X_scalered = sscaler.transform(va_X)\n",
    "    \n",
    "    #モデル学習(ランダムフォレストとした)\n",
    "    rfc = RandomForestClassifier(n_estimators=1,criterion=\"gini\",max_depth=10,random_state=1,min_samples_split = 5)\n",
    "    rfc.fit(tr_X_scalered,tr_y)\n",
    "    predicted_label = rfc.predict_proba(va_X_scalered)\n",
    "    \n",
    "    #スコア算出\n",
    "    score = roc_auc_score(va_y,predicted_label[:,1])\n",
    "    \n",
    "    #スコアを記録\n",
    "    score_probs.append(score)\n",
    "\n",
    "print(score_probs)\n",
    "print(np.mean(score_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】グリッドサーチ\n",
    "これまで分類器のパラメータには触れず、デフォルトの設定を使用していました。パラメータの詳細は今後のSprintで学んでいくことになります。機械学習の前提として、パラメータは状況に応じて最適なものを選ぶ必要があります。最適なパラメータを探していくことを パラメータチューニング と呼びます。パラメータチューニングをある程度自動化する単純な方法としては グリッドサーチ があります。\n",
    "\n",
    "\n",
    "scikit-learnのGridSearchCVを使い、グリッドサーチを行うコードを作成してください。そして、ベースラインモデルに対して何らかしらのパラメータチューニングを行なってください。どのパラメータをチューニングするかは、使用した手法の公式ドキュメントを参考にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ランダムフォレスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6933924423182928, 0.6798055260256712, 0.6805350170951292, 0.6893350305502793]\n",
      "0.6857670039973431\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4,random_state=1)\n",
    "score_probs = []\n",
    "\n",
    "for tr_idx, va_idx in kf.split(X,y):\n",
    "    # 学習データとバリデーションに分ける\n",
    "    tr_X, va_X = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    \n",
    "    # 標準化\n",
    "    sscaler = StandardScaler()\n",
    "    sscaler.fit(tr_X)\n",
    "    tr_X_scalered = sscaler.transform(tr_X)\n",
    "    va_X_scalered = sscaler.transform(va_X)\n",
    "    \n",
    "    #モデル学習\n",
    "    rfc = RandomForestClassifier(n_estimators=1,criterion=\"gini\",max_depth=10,random_state=1,min_samples_split = 5)\n",
    "    rfc.fit(tr_X_scalered,tr_y)\n",
    "    predicted_label = rfc.predict_proba(va_X_scalered)\n",
    "    \n",
    "    #スコア算出\n",
    "    score = roc_auc_score(va_y,predicted_label[:,1])\n",
    "    \n",
    "    #スコアを記録\n",
    "    score_probs.append(score)\n",
    "\n",
    "print(score_probs)\n",
    "print(np.mean(score_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "[CV] max_depth=1, min_samples_split=2 ................................\n",
      "[CV] ................. max_depth=1, min_samples_split=2, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=2 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. max_depth=1, min_samples_split=2, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=2 ................................\n",
      "[CV] ................. max_depth=1, min_samples_split=2, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=2 ................................\n",
      "[CV] ................. max_depth=1, min_samples_split=2, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=7 ................................\n",
      "[CV] ................. max_depth=1, min_samples_split=7, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=7 ................................\n",
      "[CV] ................. max_depth=1, min_samples_split=7, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=7 ................................\n",
      "[CV] ................. max_depth=1, min_samples_split=7, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=7 ................................\n",
      "[CV] ................. max_depth=1, min_samples_split=7, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=12 ...............................\n",
      "[CV] ................ max_depth=1, min_samples_split=12, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=12 ...............................\n",
      "[CV] ................ max_depth=1, min_samples_split=12, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=12 ...............................\n",
      "[CV] ................ max_depth=1, min_samples_split=12, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=12 ...............................\n",
      "[CV] ................ max_depth=1, min_samples_split=12, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=17 ...............................\n",
      "[CV] ................ max_depth=1, min_samples_split=17, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=17 ...............................\n",
      "[CV] ................ max_depth=1, min_samples_split=17, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=17 ...............................\n",
      "[CV] ................ max_depth=1, min_samples_split=17, total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=17 ...............................\n",
      "[CV] ................ max_depth=1, min_samples_split=17, total=   0.2s\n",
      "[CV] max_depth=6, min_samples_split=2 ................................\n",
      "[CV] ................. max_depth=6, min_samples_split=2, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=2 ................................\n",
      "[CV] ................. max_depth=6, min_samples_split=2, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=2 ................................\n",
      "[CV] ................. max_depth=6, min_samples_split=2, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=2 ................................\n",
      "[CV] ................. max_depth=6, min_samples_split=2, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=7 ................................\n",
      "[CV] ................. max_depth=6, min_samples_split=7, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=7 ................................\n",
      "[CV] ................. max_depth=6, min_samples_split=7, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=7 ................................\n",
      "[CV] ................. max_depth=6, min_samples_split=7, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=7 ................................\n",
      "[CV] ................. max_depth=6, min_samples_split=7, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=12 ...............................\n",
      "[CV] ................ max_depth=6, min_samples_split=12, total=   0.6s\n",
      "[CV] max_depth=6, min_samples_split=12 ...............................\n",
      "[CV] ................ max_depth=6, min_samples_split=12, total=   0.6s\n",
      "[CV] max_depth=6, min_samples_split=12 ...............................\n",
      "[CV] ................ max_depth=6, min_samples_split=12, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=12 ...............................\n",
      "[CV] ................ max_depth=6, min_samples_split=12, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=17 ...............................\n",
      "[CV] ................ max_depth=6, min_samples_split=17, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=17 ...............................\n",
      "[CV] ................ max_depth=6, min_samples_split=17, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=17 ...............................\n",
      "[CV] ................ max_depth=6, min_samples_split=17, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_split=17 ...............................\n",
      "[CV] ................ max_depth=6, min_samples_split=17, total=   0.5s\n",
      "[CV] max_depth=11, min_samples_split=2 ...............................\n",
      "[CV] ................ max_depth=11, min_samples_split=2, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=2 ...............................\n",
      "[CV] ................ max_depth=11, min_samples_split=2, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=2 ...............................\n",
      "[CV] ................ max_depth=11, min_samples_split=2, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=2 ...............................\n",
      "[CV] ................ max_depth=11, min_samples_split=2, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=7 ...............................\n",
      "[CV] ................ max_depth=11, min_samples_split=7, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=7 ...............................\n",
      "[CV] ................ max_depth=11, min_samples_split=7, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=7 ...............................\n",
      "[CV] ................ max_depth=11, min_samples_split=7, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=7 ...............................\n",
      "[CV] ................ max_depth=11, min_samples_split=7, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=12 ..............................\n",
      "[CV] ............... max_depth=11, min_samples_split=12, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=12 ..............................\n",
      "[CV] ............... max_depth=11, min_samples_split=12, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=12 ..............................\n",
      "[CV] ............... max_depth=11, min_samples_split=12, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=12 ..............................\n",
      "[CV] ............... max_depth=11, min_samples_split=12, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=17 ..............................\n",
      "[CV] ............... max_depth=11, min_samples_split=17, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=17 ..............................\n",
      "[CV] ............... max_depth=11, min_samples_split=17, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=17 ..............................\n",
      "[CV] ............... max_depth=11, min_samples_split=17, total=   0.8s\n",
      "[CV] max_depth=11, min_samples_split=17 ..............................\n",
      "[CV] ............... max_depth=11, min_samples_split=17, total=   0.8s\n",
      "[CV] max_depth=16, min_samples_split=2 ...............................\n",
      "[CV] ................ max_depth=16, min_samples_split=2, total=   1.0s\n",
      "[CV] max_depth=16, min_samples_split=2 ...............................\n",
      "[CV] ................ max_depth=16, min_samples_split=2, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=2 ...............................\n",
      "[CV] ................ max_depth=16, min_samples_split=2, total=   1.0s\n",
      "[CV] max_depth=16, min_samples_split=2 ...............................\n",
      "[CV] ................ max_depth=16, min_samples_split=2, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=7 ...............................\n",
      "[CV] ................ max_depth=16, min_samples_split=7, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=7 ...............................\n",
      "[CV] ................ max_depth=16, min_samples_split=7, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=7 ...............................\n",
      "[CV] ................ max_depth=16, min_samples_split=7, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=7 ...............................\n",
      "[CV] ................ max_depth=16, min_samples_split=7, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=12 ..............................\n",
      "[CV] ............... max_depth=16, min_samples_split=12, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=12 ..............................\n",
      "[CV] ............... max_depth=16, min_samples_split=12, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=12 ..............................\n",
      "[CV] ............... max_depth=16, min_samples_split=12, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=12 ..............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... max_depth=16, min_samples_split=12, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=17 ..............................\n",
      "[CV] ............... max_depth=16, min_samples_split=17, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=17 ..............................\n",
      "[CV] ............... max_depth=16, min_samples_split=17, total=   1.1s\n",
      "[CV] max_depth=16, min_samples_split=17 ..............................\n",
      "[CV] ............... max_depth=16, min_samples_split=17, total=   1.0s\n",
      "[CV] max_depth=16, min_samples_split=17 ..............................\n",
      "[CV] ............... max_depth=16, min_samples_split=17, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:   41.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False, random_state=1,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [1, 6, 11, 16],\n",
       "                         'min_samples_split': [2, 7, 12, 17]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#　グリッドサーチを実施。チューニングパラメータは'max_depth'、'min_samples_split'　とした。\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "def param():\n",
    "  ret = {\n",
    "      'max_depth':[i for i in range(1, 21,5)],\n",
    "      'min_samples_split':[i for i in range(2, 21,5)]\n",
    "  }\n",
    "  return ret\n",
    "\n",
    "sscaler = StandardScaler()\n",
    "sscaler.fit(x_train)\n",
    "X_scalered = sscaler.transform(x_train)\n",
    "\n",
    "gscv = GridSearchCV(RandomForestClassifier(n_estimators=10,random_state=1), param(), cv=4, verbose=2,scoring=\"roc_auc\")\n",
    "gscv.fit(X_scalered, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'min_samples_split': 17}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スコアの高かったパラメータを表示\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.158156</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.696687</td>\n",
       "      <td>0.691999</td>\n",
       "      <td>0.700022</td>\n",
       "      <td>0.702674</td>\n",
       "      <td>0.697846</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.149733</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 7}</td>\n",
       "      <td>0.696687</td>\n",
       "      <td>0.691999</td>\n",
       "      <td>0.700022</td>\n",
       "      <td>0.702674</td>\n",
       "      <td>0.697846</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.155608</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 12}</td>\n",
       "      <td>0.696687</td>\n",
       "      <td>0.691999</td>\n",
       "      <td>0.700022</td>\n",
       "      <td>0.702674</td>\n",
       "      <td>0.697846</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.147670</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.011937</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 17}</td>\n",
       "      <td>0.696687</td>\n",
       "      <td>0.691999</td>\n",
       "      <td>0.700022</td>\n",
       "      <td>0.702674</td>\n",
       "      <td>0.697846</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.511192</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>0.018407</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 2}</td>\n",
       "      <td>0.734891</td>\n",
       "      <td>0.727168</td>\n",
       "      <td>0.738790</td>\n",
       "      <td>0.743512</td>\n",
       "      <td>0.736090</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.502232</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.017726</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 7}</td>\n",
       "      <td>0.734849</td>\n",
       "      <td>0.726602</td>\n",
       "      <td>0.738356</td>\n",
       "      <td>0.743015</td>\n",
       "      <td>0.735705</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.533341</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.018553</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 12}</td>\n",
       "      <td>0.734855</td>\n",
       "      <td>0.727067</td>\n",
       "      <td>0.739588</td>\n",
       "      <td>0.742024</td>\n",
       "      <td>0.735884</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.505253</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>0.017824</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 17}</td>\n",
       "      <td>0.735511</td>\n",
       "      <td>0.727246</td>\n",
       "      <td>0.739585</td>\n",
       "      <td>0.744370</td>\n",
       "      <td>0.736678</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.800197</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.024738</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_split': 2}</td>\n",
       "      <td>0.724729</td>\n",
       "      <td>0.721851</td>\n",
       "      <td>0.724373</td>\n",
       "      <td>0.729336</td>\n",
       "      <td>0.725072</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.790332</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.025077</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_split': 7}</td>\n",
       "      <td>0.727538</td>\n",
       "      <td>0.717252</td>\n",
       "      <td>0.724763</td>\n",
       "      <td>0.732059</td>\n",
       "      <td>0.725403</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.793447</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.024509</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_split': 12}</td>\n",
       "      <td>0.729120</td>\n",
       "      <td>0.716331</td>\n",
       "      <td>0.723663</td>\n",
       "      <td>0.732887</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.795592</td>\n",
       "      <td>0.011495</td>\n",
       "      <td>0.024997</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_split': 17}</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.717463</td>\n",
       "      <td>0.724040</td>\n",
       "      <td>0.736718</td>\n",
       "      <td>0.725633</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.022666</td>\n",
       "      <td>0.015657</td>\n",
       "      <td>0.032492</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 16, 'min_samples_split': 2}</td>\n",
       "      <td>0.691895</td>\n",
       "      <td>0.678167</td>\n",
       "      <td>0.683040</td>\n",
       "      <td>0.694225</td>\n",
       "      <td>0.686831</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.075300</td>\n",
       "      <td>0.026478</td>\n",
       "      <td>0.034706</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 16, 'min_samples_split': 7}</td>\n",
       "      <td>0.698008</td>\n",
       "      <td>0.683144</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.698475</td>\n",
       "      <td>0.692204</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.087406</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.034571</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 16, 'min_samples_split': 12}</td>\n",
       "      <td>0.703077</td>\n",
       "      <td>0.683590</td>\n",
       "      <td>0.688280</td>\n",
       "      <td>0.708491</td>\n",
       "      <td>0.695859</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.022335</td>\n",
       "      <td>0.039404</td>\n",
       "      <td>0.031766</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 16, 'min_samples_split': 17}</td>\n",
       "      <td>0.706320</td>\n",
       "      <td>0.701433</td>\n",
       "      <td>0.701294</td>\n",
       "      <td>0.705855</td>\n",
       "      <td>0.703726</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.158156      0.012917         0.011643        0.000184   \n",
       "1        0.149733      0.007400         0.011869        0.000426   \n",
       "2        0.155608      0.003677         0.012498        0.000651   \n",
       "3        0.147670      0.001387         0.011937        0.000192   \n",
       "4        0.511192      0.010664         0.018407        0.000580   \n",
       "5        0.502232      0.007082         0.017726        0.000767   \n",
       "6        0.533341      0.015679         0.018553        0.000753   \n",
       "7        0.505253      0.008604         0.017824        0.000231   \n",
       "8        0.800197      0.005398         0.024738        0.000206   \n",
       "9        0.790332      0.002945         0.025077        0.000449   \n",
       "10       0.793447      0.002954         0.024509        0.000346   \n",
       "11       0.795592      0.011495         0.024997        0.000809   \n",
       "12       1.022666      0.015657         0.032492        0.000251   \n",
       "13       1.075300      0.026478         0.034706        0.001324   \n",
       "14       1.087406      0.006757         0.034571        0.000520   \n",
       "15       1.022335      0.039404         0.031766        0.000499   \n",
       "\n",
       "   param_max_depth param_min_samples_split  \\\n",
       "0                1                       2   \n",
       "1                1                       7   \n",
       "2                1                      12   \n",
       "3                1                      17   \n",
       "4                6                       2   \n",
       "5                6                       7   \n",
       "6                6                      12   \n",
       "7                6                      17   \n",
       "8               11                       2   \n",
       "9               11                       7   \n",
       "10              11                      12   \n",
       "11              11                      17   \n",
       "12              16                       2   \n",
       "13              16                       7   \n",
       "14              16                      12   \n",
       "15              16                      17   \n",
       "\n",
       "                                        params  split0_test_score  \\\n",
       "0     {'max_depth': 1, 'min_samples_split': 2}           0.696687   \n",
       "1     {'max_depth': 1, 'min_samples_split': 7}           0.696687   \n",
       "2    {'max_depth': 1, 'min_samples_split': 12}           0.696687   \n",
       "3    {'max_depth': 1, 'min_samples_split': 17}           0.696687   \n",
       "4     {'max_depth': 6, 'min_samples_split': 2}           0.734891   \n",
       "5     {'max_depth': 6, 'min_samples_split': 7}           0.734849   \n",
       "6    {'max_depth': 6, 'min_samples_split': 12}           0.734855   \n",
       "7    {'max_depth': 6, 'min_samples_split': 17}           0.735511   \n",
       "8    {'max_depth': 11, 'min_samples_split': 2}           0.724729   \n",
       "9    {'max_depth': 11, 'min_samples_split': 7}           0.727538   \n",
       "10  {'max_depth': 11, 'min_samples_split': 12}           0.729120   \n",
       "11  {'max_depth': 11, 'min_samples_split': 17}           0.724311   \n",
       "12   {'max_depth': 16, 'min_samples_split': 2}           0.691895   \n",
       "13   {'max_depth': 16, 'min_samples_split': 7}           0.698008   \n",
       "14  {'max_depth': 16, 'min_samples_split': 12}           0.703077   \n",
       "15  {'max_depth': 16, 'min_samples_split': 17}           0.706320   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0            0.691999           0.700022           0.702674         0.697846   \n",
       "1            0.691999           0.700022           0.702674         0.697846   \n",
       "2            0.691999           0.700022           0.702674         0.697846   \n",
       "3            0.691999           0.700022           0.702674         0.697846   \n",
       "4            0.727168           0.738790           0.743512         0.736090   \n",
       "5            0.726602           0.738356           0.743015         0.735705   \n",
       "6            0.727067           0.739588           0.742024         0.735884   \n",
       "7            0.727246           0.739585           0.744370         0.736678   \n",
       "8            0.721851           0.724373           0.729336         0.725072   \n",
       "9            0.717252           0.724763           0.732059         0.725403   \n",
       "10           0.716331           0.723663           0.732887         0.725500   \n",
       "11           0.717463           0.724040           0.736718         0.725633   \n",
       "12           0.678167           0.683040           0.694225         0.686831   \n",
       "13           0.683144           0.689189           0.698475         0.692204   \n",
       "14           0.683590           0.688280           0.708491         0.695859   \n",
       "15           0.701433           0.701294           0.705855         0.703726   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.003987               10  \n",
       "1         0.003987               10  \n",
       "2         0.003987               10  \n",
       "3         0.003987               10  \n",
       "4         0.005988                2  \n",
       "5         0.006001                4  \n",
       "6         0.005706                3  \n",
       "7         0.006284                1  \n",
       "8         0.002700                8  \n",
       "9         0.005378                7  \n",
       "10        0.006228                6  \n",
       "11        0.006963                5  \n",
       "12        0.006514               16  \n",
       "13        0.006407               15  \n",
       "14        0.010243               14  \n",
       "15        0.002368                9  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 参考として計算結果を表示\n",
    "gs_result = pd.DataFrame.from_dict(gscv.cv_results_) #詳細表示\n",
    "gs_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7433423876632538"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valデータで最も良かったモデルで評価。スコアを表示\n",
    "\n",
    "X_test_scalered = sscaler.transform(x_test)\n",
    "\n",
    "best_clf = gscv.best_estimator_\n",
    "predicted_label = best_clf.predict_proba(X_test_scalered)\n",
    "score = roc_auc_score(y_test,predicted_label[:,1])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7256212398614064, 0.7182434148358138, 0.7237825346250573, 0.7272273278821558]\n",
      "0.7237186293011083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4,random_state=1)\n",
    "score_probs = []\n",
    "\n",
    "for tr_idx, va_idx in kf.split(X,y):\n",
    "    # 学習データとバリデーションに分ける\n",
    "    tr_X, va_X = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    \n",
    "    # 標準化\n",
    "    sscaler = StandardScaler()\n",
    "    sscaler.fit(tr_X)\n",
    "    tr_X_scalered = sscaler.transform(tr_X)\n",
    "    va_X_scalered = sscaler.transform(va_X)\n",
    "    \n",
    "    #モデル学習\n",
    "    rfc = RandomForestClassifier(n_estimators=1,criterion=\"gini\",max_depth=6,random_state=1,min_samples_split = 7)\n",
    "    rfc.fit(tr_X_scalered,tr_y)\n",
    "    predicted_label = rfc.predict_proba(va_X_scalered)\n",
    "    \n",
    "    #スコア算出\n",
    "    score = roc_auc_score(va_y,predicted_label[:,1])\n",
    "    \n",
    "    #スコアを記録\n",
    "    score_probs.append(score)\n",
    "\n",
    "print(score_probs)\n",
    "print(np.mean(score_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】Kaggle Notebooksからの調査\n",
    "KaggleのNotebooksから様々なアイデアを見つけ出して、列挙してください。\n",
    "\n",
    ">xgboost\n",
    "\n",
    ">lightgbm\n",
    "\n",
    ">early_stopping_rounds\n",
    "\n",
    ">lgb.plot_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】高い汎化性能のモデル作成\n",
    "問題3で見つけたアイデアと、独自のアイデアを組み合わせ高い汎化性能のモデル作りを進めてください。\n",
    "その過程として、何を行うことで、クロスバリデーションの結果がどの程度変化したかを表にまとめてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboostはカグル上位者でもよく使われるモデルであり、勾配ブースティングという弱学習器に決定木を直列に幾度も計算させ目的関数の結果に重みをつけて次の学習を繰り返すことで目的関数を最小化する。そのため、精度も上げやすいと言われている。\n",
    "今回、これまでと同様のデータに対して、xgboosによるモデルと、これまでのクロスバリデーションを組み合わせて、高い汎化性能を実現できるか確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mishibatoshihiro/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/mishibatoshihiro/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/mishibatoshihiro/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/mishibatoshihiro/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7397841562327742, 0.7425126978502243, 0.7401902876786847, 0.7428258760635977]\n",
      "0.7413282544563202\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4)\n",
    "score_probs = []\n",
    "\n",
    "for tr_idx, va_idx in kf.split(X,y):\n",
    "    # 学習データとバリデーションに分ける\n",
    "    tr_X, va_X = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    \n",
    "    # 標準化\n",
    "    sscaler = StandardScaler()\n",
    "    sscaler.fit(tr_X)\n",
    "    tr_X_scalered = sscaler.transform(tr_X)\n",
    "    va_X_scalered = sscaler.transform(va_X)\n",
    "    \n",
    "    # XGBoost が扱うデータセットの形式に直す\n",
    "    dtrain = xgb.DMatrix(tr_X_scalered, label=tr_y)\n",
    "    dtest = xgb.DMatrix(va_X_scalered, label=va_y)\n",
    "    \n",
    "    #モデル学習\n",
    "    params={'booster':'gbtree','objective':'binary:logistic','eval_metric': 'logloss','eta':0.1,'gamma':0,'alpha':0,'lambda':1,'min_child_weight':1,'maxdepth':5,'subsample':0.8,'colsample':0.8,'cosample_bytree':0.8,'ramdom_state':71}\n",
    "    num_round=100\n",
    "    bst = xgb.train(params,\n",
    "                    dtrain,\n",
    "                    num_round\n",
    "                    )\n",
    "    \n",
    "    #確率予測を返す\n",
    "    predicted_label = bst.predict(dtest)\n",
    "    \n",
    "    #スコア算出\n",
    "    score = roc_auc_score(va_y,predicted_label)\n",
    "    \n",
    "    #スコアを記録\n",
    "    score_probs.append(score)\n",
    "\n",
    "print(score_probs)\n",
    "print(np.mean(score_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果、ランダムフォレストではAUC平均：0.685（チューニングなし）、AUC平均：0.723（チューニングなし）に対し、今回のxgboostではAUC平均：0.741であり精度向上された。かつ、クロスバリデーションでの4fold分の結果も偏りなくAUC値も出せているため、汎化性能も高いと考えられる。\n",
    "\n",
    "さらにカグルでのカーネルに学習モデルとしてlightgbmも紹介されていた。これは、xgboostと基本的にGBDT（勾配ブースティング木）であることは同じであるが、Leaf-wiseという決定木を全体で見渡して、「分岐させるべき葉」を優先的に分岐させ流ことができる。（xgboostはLeave-wiseで「層ごとに一括で」分岐を進める）また、訓練データをヒストグラム化して計算するので非常に細かい数値だったデータがヒストグラムにすることで「大雑把にまとめられた」データになり高速でモデル構築を進めることができる。以下lightgbmも今回のクロスバリデーションと組み合わせ確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mishibatoshihiro/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's binary_logloss: 0.238444\n",
      "[20]\tvalid_0's binary_logloss: 0.234626\n",
      "[30]\tvalid_0's binary_logloss: 0.233845\n",
      "[40]\tvalid_0's binary_logloss: 0.233692\n",
      "[50]\tvalid_0's binary_logloss: 0.23391\n",
      "[60]\tvalid_0's binary_logloss: 0.233935\n",
      "[70]\tvalid_0's binary_logloss: 0.233948\n",
      "[80]\tvalid_0's binary_logloss: 0.234098\n",
      "[90]\tvalid_0's binary_logloss: 0.234234\n",
      "[100]\tvalid_0's binary_logloss: 0.234401\n",
      "[10]\tvalid_0's binary_logloss: 0.237799\n",
      "[20]\tvalid_0's binary_logloss: 0.233797\n",
      "[30]\tvalid_0's binary_logloss: 0.232913\n",
      "[40]\tvalid_0's binary_logloss: 0.232692\n",
      "[50]\tvalid_0's binary_logloss: 0.232562\n",
      "[60]\tvalid_0's binary_logloss: 0.232548\n",
      "[70]\tvalid_0's binary_logloss: 0.232787\n",
      "[80]\tvalid_0's binary_logloss: 0.232923\n",
      "[90]\tvalid_0's binary_logloss: 0.233027\n",
      "[100]\tvalid_0's binary_logloss: 0.233148\n",
      "[10]\tvalid_0's binary_logloss: 0.238769\n",
      "[20]\tvalid_0's binary_logloss: 0.234882\n",
      "[30]\tvalid_0's binary_logloss: 0.234016\n",
      "[40]\tvalid_0's binary_logloss: 0.233827\n",
      "[50]\tvalid_0's binary_logloss: 0.233827\n",
      "[60]\tvalid_0's binary_logloss: 0.233904\n",
      "[70]\tvalid_0's binary_logloss: 0.233988\n",
      "[80]\tvalid_0's binary_logloss: 0.234037\n",
      "[90]\tvalid_0's binary_logloss: 0.234214\n",
      "[100]\tvalid_0's binary_logloss: 0.23419\n",
      "[10]\tvalid_0's binary_logloss: 0.23858\n",
      "[20]\tvalid_0's binary_logloss: 0.234717\n",
      "[30]\tvalid_0's binary_logloss: 0.233736\n",
      "[40]\tvalid_0's binary_logloss: 0.233561\n",
      "[50]\tvalid_0's binary_logloss: 0.233568\n",
      "[60]\tvalid_0's binary_logloss: 0.233671\n",
      "[70]\tvalid_0's binary_logloss: 0.233808\n",
      "[80]\tvalid_0's binary_logloss: 0.233818\n",
      "[90]\tvalid_0's binary_logloss: 0.23391\n",
      "[100]\tvalid_0's binary_logloss: 0.234042\n",
      "[0.7410981474919285, 0.7428695960311835, 0.7415189207329076, 0.7419143875201766]\n",
      "0.7418502629440491\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4)\n",
    "score_probs_gbm = []\n",
    "\n",
    "for tr_idx, va_idx in kf.split(X,y):\n",
    "    # 学習データとバリデーションに分ける\n",
    "    tr_X, va_X = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    \n",
    "    # 標準化\n",
    "    sscaler = StandardScaler()\n",
    "    sscaler.fit(tr_X)\n",
    "    tr_X_scalered = sscaler.transform(tr_X)\n",
    "    va_X_scalered = sscaler.transform(va_X)\n",
    "    \n",
    "    # lightgbm が扱うデータセットの形式に直す\n",
    "    dtrain = lgb.Dataset(tr_X_scalered, label=tr_y)\n",
    "    dtest = lgb.Dataset(va_X_scalered, label=va_y, reference= dtrain)\n",
    "    \n",
    "    #モデル学習\n",
    "    params= {'objective':'binary','learning_rate':0.1,'reg_alpha':0,'leg_lambda':1,'min_child_weight':1,'max_depth':5,'subsample':0.8,'colsample':0.8,'colsample_bytree':0.8,'ramdom_state':71}\n",
    "    gbm = lgb.train(params,\n",
    "                    dtrain,\n",
    "                    valid_sets=dtest,\n",
    "                    num_boost_round=100,\n",
    "                    verbose_eval=10\n",
    "                    )\n",
    "    \n",
    "    #確率予測を返す\n",
    "    predicted_label_gbm = gbm.predict(va_X_scalered)\n",
    "    \n",
    "    #スコア算出\n",
    "    score_gbm = roc_auc_score(va_y,predicted_label_gbm)\n",
    "    \n",
    "    #スコアを記録\n",
    "    score_probs_gbm.append(score_gbm)\n",
    "\n",
    "print(score_probs_gbm)\n",
    "print(np.mean(score_probs_gbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この結果からAUC平均：0.742でほぼxgboostと同等の評価結果となることが分かった。\n",
    "しかし、バリデーションデータの目的関数logglossの途中結果を観察すると、学習が100回未満の地点で最小になり、そこから大きくなってしまっていることがわかる。\n",
    "（Fold1:約40〜50回地点、Fold2:約60〜70回地点、Fold3:約40〜50回地点、Fold4:約40〜50回地点）よって、それ以上学習してtrainデータをか学習してバリデーションデータに対する予測を下げないために、目的関数が最小になったところで止める必要がある。\n",
    "この手法として、**early_stopping_rounds**　がカグルで紹介されていた。この数値を規定すると、その数値の回数まで観察をしてみて目的関数が最小のところで評価可能であるとのことでこちらを使い同様に評価を行ってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.238444\n",
      "[20]\tvalid_0's binary_logloss: 0.234626\n",
      "[30]\tvalid_0's binary_logloss: 0.233845\n",
      "[40]\tvalid_0's binary_logloss: 0.233692\n",
      "[50]\tvalid_0's binary_logloss: 0.23391\n",
      "[60]\tvalid_0's binary_logloss: 0.233935\n",
      "[70]\tvalid_0's binary_logloss: 0.233948\n",
      "[80]\tvalid_0's binary_logloss: 0.234098\n",
      "[90]\tvalid_0's binary_logloss: 0.234234\n",
      "[100]\tvalid_0's binary_logloss: 0.234401\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[40]\tvalid_0's binary_logloss: 0.233692\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.237799\n",
      "[20]\tvalid_0's binary_logloss: 0.233797\n",
      "[30]\tvalid_0's binary_logloss: 0.232913\n",
      "[40]\tvalid_0's binary_logloss: 0.232692\n",
      "[50]\tvalid_0's binary_logloss: 0.232562\n",
      "[60]\tvalid_0's binary_logloss: 0.232548\n",
      "[70]\tvalid_0's binary_logloss: 0.232787\n",
      "[80]\tvalid_0's binary_logloss: 0.232923\n",
      "[90]\tvalid_0's binary_logloss: 0.233027\n",
      "[100]\tvalid_0's binary_logloss: 0.233148\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[60]\tvalid_0's binary_logloss: 0.232548\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.238769\n",
      "[20]\tvalid_0's binary_logloss: 0.234882\n",
      "[30]\tvalid_0's binary_logloss: 0.234016\n",
      "[40]\tvalid_0's binary_logloss: 0.233827\n",
      "[50]\tvalid_0's binary_logloss: 0.233827\n",
      "[60]\tvalid_0's binary_logloss: 0.233904\n",
      "[70]\tvalid_0's binary_logloss: 0.233988\n",
      "[80]\tvalid_0's binary_logloss: 0.234037\n",
      "[90]\tvalid_0's binary_logloss: 0.234214\n",
      "[100]\tvalid_0's binary_logloss: 0.23419\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[46]\tvalid_0's binary_logloss: 0.233787\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.23858\n",
      "[20]\tvalid_0's binary_logloss: 0.234717\n",
      "[30]\tvalid_0's binary_logloss: 0.233736\n",
      "[40]\tvalid_0's binary_logloss: 0.233561\n",
      "[50]\tvalid_0's binary_logloss: 0.233568\n",
      "[60]\tvalid_0's binary_logloss: 0.233671\n",
      "[70]\tvalid_0's binary_logloss: 0.233808\n",
      "[80]\tvalid_0's binary_logloss: 0.233818\n",
      "[90]\tvalid_0's binary_logloss: 0.23391\n",
      "[100]\tvalid_0's binary_logloss: 0.234042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[42]\tvalid_0's binary_logloss: 0.233515\n",
      "[0.7436548547129695, 0.7450032876604458, 0.7432706332692294, 0.7442807516291123]\n",
      "0.7440523818179392\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4)\n",
    "score_probs_gbm = []\n",
    "\n",
    "for tr_idx, va_idx in kf.split(X,y):\n",
    "    # 学習データとバリデーションに分ける\n",
    "    tr_X, va_X = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    \n",
    "    # 標準化\n",
    "    sscaler = StandardScaler()\n",
    "    sscaler.fit(tr_X)\n",
    "    tr_X_scalered = sscaler.transform(tr_X)\n",
    "    va_X_scalered = sscaler.transform(va_X)\n",
    "    \n",
    "    # lightgbm が扱うデータセットの形式に直す\n",
    "    dtrain = lgb.Dataset(tr_X_scalered, label=tr_y)\n",
    "    dtest = lgb.Dataset(va_X_scalered, label=va_y, reference= dtrain)\n",
    "    \n",
    "    #モデル学習\n",
    "    params= {'objective':'binary','learning_rate':0.1,'reg_alpha':0,'leg_lambda':1,'min_child_weight':1,'max_depth':5,'subsample':0.8,'colsample':0.8,'colsample_bytree':0.8,'ramdom_state':71}\n",
    "    gbm = lgb.train(params,\n",
    "                    dtrain,\n",
    "                    valid_sets=dtest,\n",
    "                    num_boost_round=100,\n",
    "                    verbose_eval=10,\n",
    "                    early_stopping_rounds=80,\n",
    "                    )\n",
    "    \n",
    "    #確率予測を返す\n",
    "    predicted_label_gbm = gbm.predict(va_X_scalered)\n",
    "    \n",
    "    #スコア算出\n",
    "    score_gbm = roc_auc_score(va_y,predicted_label_gbm)\n",
    "    \n",
    "    #スコアを記録\n",
    "    score_probs_gbm.append(score_gbm)\n",
    "\n",
    "print(score_probs_gbm)\n",
    "print(np.mean(score_probs_gbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "狙い通り、100回未満の目的関数が最小の地点で評価できていることがわかる。\n",
    "（Fold1:40回地点、Fold2:60回地点、Fold3:46回地点、Fold4:42回地点）\n",
    "AUC平均：0.744で前回のAUC平均：0.741よりも少しではあるが向上していることを確認できた。\n",
    "最後にこのlightgbmでグリッドサーチを実施する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=31 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=31, score=(train=0.744, test=0.726), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=31 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=31, score=(train=0.743, test=0.738), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=31 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=31, score=(train=0.746, test=0.731), total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=31 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=31, score=(train=0.745, test=0.722), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=100 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=100, score=(train=0.744, test=0.727), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=100 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=100, score=(train=0.743, test=0.739), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=100 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=100, score=(train=0.747, test=0.732), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=100 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=100, score=(train=0.747, test=0.723), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=300 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=300, score=(train=0.744, test=0.727), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=300 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=300, score=(train=0.743, test=0.739), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=300, score=(train=0.747, test=0.732), total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=300, score=(train=0.747, test=0.723), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=500, score=(train=0.744, test=0.727), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=500, score=(train=0.743, test=0.739), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=500, score=(train=0.747, test=0.732), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=5, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.001, max_depth=5, num_leaves=500, score=(train=0.747, test=0.723), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=31, score=(train=0.745, test=0.728), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=31, score=(train=0.743, test=0.738), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=31, score=(train=0.746, test=0.731), total=   0.5s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=31, score=(train=0.744, test=0.721), total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=100, score=(train=0.762, test=0.729), total=   0.6s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=100, score=(train=0.761, test=0.738), total=   0.5s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=100, score=(train=0.763, test=0.735), total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=100, score=(train=0.765, test=0.727), total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=300, score=(train=0.794, test=0.715), total=   0.9s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=300, score=(train=0.795, test=0.731), total=   1.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=300, score=(train=0.801, test=0.731), total=   1.5s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=300, score=(train=0.799, test=0.708), total=   1.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=500, score=(train=0.817, test=0.706), total=   1.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=500, score=(train=0.825, test=0.717), total=   1.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=500, score=(train=0.830, test=0.721), total=   1.3s\n",
      "[CV] learning_rate=0.001, max_depth=10, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, num_leaves=500, score=(train=0.816, test=0.699), total=   1.4s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=31, score=(train=0.745, test=0.728), total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=31, score=(train=0.743, test=0.738), total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=31, score=(train=0.746, test=0.731), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=31, score=(train=0.744, test=0.721), total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=100, score=(train=0.762, test=0.729), total=   0.5s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=100, score=(train=0.760, test=0.738), total=   0.5s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=100, score=(train=0.763, test=0.735), total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=100, score=(train=0.763, test=0.727), total=   0.5s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=300, score=(train=0.791, test=0.721), total=   0.9s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=300, score=(train=0.791, test=0.735), total=   0.9s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=300, score=(train=0.794, test=0.729), total=   0.8s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=300, score=(train=0.793, test=0.715), total=   0.8s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=500, score=(train=0.817, test=0.700), total=   1.2s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=500, score=(train=0.822, test=0.722), total=   1.3s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=500, score=(train=0.825, test=0.720), total=   1.3s\n",
      "[CV] learning_rate=0.001, max_depth=25, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=25, num_leaves=500, score=(train=0.816, test=0.696), total=   1.3s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=31, score=(train=0.745, test=0.728), total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=31, score=(train=0.743, test=0.738), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=31, score=(train=0.746, test=0.731), total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=31 ................\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=31, score=(train=0.744, test=0.721), total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=100, score=(train=0.762, test=0.729), total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=100, score=(train=0.760, test=0.738), total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=100, score=(train=0.763, test=0.735), total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=100 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=100, score=(train=0.763, test=0.727), total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=300 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=300, score=(train=0.791, test=0.721), total=   0.9s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=300, score=(train=0.791, test=0.735), total=   0.9s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=300, score=(train=0.794, test=0.729), total=   1.0s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=300 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=300, score=(train=0.793, test=0.715), total=   0.9s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=500, score=(train=0.817, test=0.700), total=   1.3s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=500, score=(train=0.822, test=0.722), total=   1.3s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=500, score=(train=0.825, test=0.720), total=   1.2s\n",
      "[CV] learning_rate=0.001, max_depth=50, num_leaves=500 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=50, num_leaves=500, score=(train=0.816, test=0.696), total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=31, score=(train=0.759, test=0.739), total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=31, score=(train=0.757, test=0.745), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=31, score=(train=0.759, test=0.739), total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=31, score=(train=0.760, test=0.736), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=100, score=(train=0.760, test=0.740), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=100, score=(train=0.757, test=0.745), total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=100, score=(train=0.759, test=0.739), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=100, score=(train=0.760, test=0.736), total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=300, score=(train=0.760, test=0.740), total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=300, score=(train=0.757, test=0.745), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=300, score=(train=0.759, test=0.739), total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=300, score=(train=0.760, test=0.736), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=500, score=(train=0.760, test=0.740), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=500, score=(train=0.757, test=0.745), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=500, score=(train=0.759, test=0.739), total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=5, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.01, max_depth=5, num_leaves=500, score=(train=0.760, test=0.736), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=31, score=(train=0.762, test=0.741), total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=31, score=(train=0.759, test=0.746), total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=31, score=(train=0.760, test=0.739), total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=31, score=(train=0.762, test=0.735), total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=100, score=(train=0.794, test=0.738), total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=100, score=(train=0.790, test=0.743), total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=100, score=(train=0.791, test=0.739), total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=100, score=(train=0.793, test=0.734), total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=300, score=(train=0.847, test=0.728), total=   2.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=300, score=(train=0.844, test=0.736), total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=300, score=(train=0.848, test=0.734), total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=300, score=(train=0.849, test=0.723), total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=500, score=(train=0.870, test=0.724), total=   1.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=500, score=(train=0.869, test=0.731), total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=500, score=(train=0.868, test=0.729), total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, num_leaves=500, score=(train=0.870, test=0.718), total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=31, score=(train=0.762, test=0.741), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=31, score=(train=0.759, test=0.746), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=31, score=(train=0.760, test=0.739), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=31, score=(train=0.762, test=0.735), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=100, score=(train=0.796, test=0.739), total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=100, score=(train=0.792, test=0.743), total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=100, score=(train=0.791, test=0.739), total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=100, score=(train=0.793, test=0.734), total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=300 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=300, score=(train=0.855, test=0.730), total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=300, score=(train=0.851, test=0.736), total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=300, score=(train=0.853, test=0.733), total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=300, score=(train=0.857, test=0.726), total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=500, score=(train=0.895, test=0.719), total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=500, score=(train=0.891, test=0.729), total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=500, score=(train=0.893, test=0.726), total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=25, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=25, num_leaves=500, score=(train=0.896, test=0.717), total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=31, score=(train=0.762, test=0.741), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=31, score=(train=0.759, test=0.746), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=31, score=(train=0.760, test=0.739), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=31 .................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=31, score=(train=0.762, test=0.735), total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=100, score=(train=0.796, test=0.739), total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=100, score=(train=0.792, test=0.743), total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=100, score=(train=0.791, test=0.739), total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=100 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=100, score=(train=0.793, test=0.734), total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=300, score=(train=0.855, test=0.730), total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=300, score=(train=0.851, test=0.736), total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=300, score=(train=0.854, test=0.732), total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=300 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=300, score=(train=0.857, test=0.726), total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=500, score=(train=0.894, test=0.720), total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=500, score=(train=0.890, test=0.729), total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=500, score=(train=0.893, test=0.726), total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=50, num_leaves=500 ................\n",
      "[CV]  learning_rate=0.01, max_depth=50, num_leaves=500, score=(train=0.896, test=0.719), total=   1.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=31 ...................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=31, score=(train=0.802, test=0.739), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=31 ...................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=31, score=(train=0.796, test=0.744), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=31 ...................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=31, score=(train=0.798, test=0.740), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=31 ...................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=31, score=(train=0.801, test=0.737), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=100 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=100, score=(train=0.801, test=0.739), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=100 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=100, score=(train=0.798, test=0.744), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=100 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=100, score=(train=0.798, test=0.740), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=100 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=100, score=(train=0.801, test=0.736), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=300 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=300, score=(train=0.801, test=0.739), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=300 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=300, score=(train=0.798, test=0.744), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=300 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=300, score=(train=0.798, test=0.740), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=300 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=300, score=(train=0.801, test=0.736), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=500 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=500, score=(train=0.801, test=0.739), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=500 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=500, score=(train=0.798, test=0.744), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=500 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=500, score=(train=0.798, test=0.740), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, num_leaves=500 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, num_leaves=500, score=(train=0.801, test=0.736), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=31, score=(train=0.829, test=0.738), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=31, score=(train=0.826, test=0.743), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=31, score=(train=0.826, test=0.738), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=31, score=(train=0.832, test=0.734), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=100, score=(train=0.910, test=0.727), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=100, score=(train=0.913, test=0.734), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=100, score=(train=0.909, test=0.725), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=100, score=(train=0.920, test=0.721), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=300 .................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=300, score=(train=0.952, test=0.719), total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=300, score=(train=0.954, test=0.723), total=   1.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=300, score=(train=0.949, test=0.721), total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=300, score=(train=0.951, test=0.713), total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=500, score=(train=0.957, test=0.716), total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=500, score=(train=0.957, test=0.723), total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=500, score=(train=0.957, test=0.723), total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, num_leaves=500, score=(train=0.960, test=0.710), total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=31, score=(train=0.831, test=0.738), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=31, score=(train=0.830, test=0.743), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=31, score=(train=0.829, test=0.739), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=31, score=(train=0.832, test=0.733), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=100, score=(train=0.929, test=0.726), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=100, score=(train=0.930, test=0.735), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=100, score=(train=0.928, test=0.727), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=100, score=(train=0.927, test=0.724), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=300, score=(train=0.992, test=0.714), total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=300, score=(train=0.993, test=0.717), total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=300, score=(train=0.993, test=0.713), total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=300, score=(train=0.991, test=0.709), total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=500, score=(train=0.999, test=0.702), total=   1.3s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=500, score=(train=0.999, test=0.710), total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=500, score=(train=1.000, test=0.707), total=   1.3s\n",
      "[CV] learning_rate=0.1, max_depth=25, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=25, num_leaves=500, score=(train=0.999, test=0.695), total=   1.3s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=31, score=(train=0.831, test=0.738), total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=31, score=(train=0.830, test=0.743), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=31, score=(train=0.829, test=0.739), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=31 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=31, score=(train=0.832, test=0.733), total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=100, score=(train=0.929, test=0.727), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=100, score=(train=0.931, test=0.734), total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=100, score=(train=0.929, test=0.728), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=100 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=100, score=(train=0.929, test=0.720), total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=300, score=(train=0.992, test=0.710), total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=300, score=(train=0.993, test=0.718), total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=300, score=(train=0.993, test=0.716), total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=300 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=300, score=(train=0.993, test=0.709), total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=500, score=(train=0.999, test=0.704), total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=500, score=(train=0.999, test=0.712), total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=500, score=(train=0.999, test=0.714), total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=50, num_leaves=500 .................\n",
      "[CV]  learning_rate=0.1, max_depth=50, num_leaves=500, score=(train=0.999, test=0.702), total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 192 out of 192 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=0, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=-1,\n",
       "                                      min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=None, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=False,\n",
       "                                      subsample=1.0, subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.001, 0.01, 0.1],\n",
       "                         'max_depth': [5, 10, 25, 50],\n",
       "                         'num_leaves': [31, 100, 300, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lightgbでのグリッドサーチ\n",
    "import lightgbm as lgb\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "X_scalered = scaler.transform(x_train)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4,shuffle=True,random_state=0)\n",
    "model2 = lgb.LGBMClassifier(silent=False)\n",
    "\n",
    "# パラメーターを設定する\n",
    "param_grid2 = {\"max_depth\": [5, 10, 25, 50],\n",
    "              \"learning_rate\" : [0.001,0.01,0.1],\n",
    "              \"num_leaves\": [31,100,300,500],\n",
    "             }\n",
    "# パラメータチューニングをグリッドサーチで行うために設定する\n",
    "## このGridSearchCV には注意が必要 scoring は そのスコアを基準にして最適化する\n",
    "grid_result = GridSearchCV(estimator = model2,\n",
    "                           param_grid = param_grid2,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = skf,\n",
    "                           verbose=10,\n",
    "                           return_train_score = True)\n",
    "\n",
    "grid_result.fit(X_scalered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 10, 'num_leaves': 31}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.193696</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.031037</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 5, 'num_...</td>\n",
       "      <td>0.726286</td>\n",
       "      <td>0.737935</td>\n",
       "      <td>0.731483</td>\n",
       "      <td>0.721501</td>\n",
       "      <td>0.729302</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>30</td>\n",
       "      <td>0.743600</td>\n",
       "      <td>0.743121</td>\n",
       "      <td>0.746197</td>\n",
       "      <td>0.745486</td>\n",
       "      <td>0.744601</td>\n",
       "      <td>0.001277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.171575</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 5, 'num_...</td>\n",
       "      <td>0.726790</td>\n",
       "      <td>0.738576</td>\n",
       "      <td>0.731976</td>\n",
       "      <td>0.722803</td>\n",
       "      <td>0.730036</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>24</td>\n",
       "      <td>0.743705</td>\n",
       "      <td>0.743319</td>\n",
       "      <td>0.746628</td>\n",
       "      <td>0.747018</td>\n",
       "      <td>0.745167</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.194387</td>\n",
       "      <td>0.046441</td>\n",
       "      <td>0.025186</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 5, 'num_...</td>\n",
       "      <td>0.726790</td>\n",
       "      <td>0.738576</td>\n",
       "      <td>0.731976</td>\n",
       "      <td>0.722803</td>\n",
       "      <td>0.730036</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>24</td>\n",
       "      <td>0.743705</td>\n",
       "      <td>0.743319</td>\n",
       "      <td>0.746628</td>\n",
       "      <td>0.747018</td>\n",
       "      <td>0.745167</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.173624</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.026249</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 5, 'num_...</td>\n",
       "      <td>0.726790</td>\n",
       "      <td>0.738576</td>\n",
       "      <td>0.731976</td>\n",
       "      <td>0.722803</td>\n",
       "      <td>0.730036</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>24</td>\n",
       "      <td>0.743705</td>\n",
       "      <td>0.743319</td>\n",
       "      <td>0.746628</td>\n",
       "      <td>0.747018</td>\n",
       "      <td>0.745167</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.303688</td>\n",
       "      <td>0.101949</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 10, 'num...</td>\n",
       "      <td>0.728448</td>\n",
       "      <td>0.737943</td>\n",
       "      <td>0.731136</td>\n",
       "      <td>0.720770</td>\n",
       "      <td>0.729574</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>27</td>\n",
       "      <td>0.745415</td>\n",
       "      <td>0.742758</td>\n",
       "      <td>0.746462</td>\n",
       "      <td>0.743572</td>\n",
       "      <td>0.744552</td>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.452661</td>\n",
       "      <td>0.080206</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 10, 'num...</td>\n",
       "      <td>0.728878</td>\n",
       "      <td>0.738260</td>\n",
       "      <td>0.734723</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.732138</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>18</td>\n",
       "      <td>0.761843</td>\n",
       "      <td>0.760675</td>\n",
       "      <td>0.763184</td>\n",
       "      <td>0.764658</td>\n",
       "      <td>0.762590</td>\n",
       "      <td>0.001488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.037155</td>\n",
       "      <td>0.236703</td>\n",
       "      <td>0.060690</td>\n",
       "      <td>0.009822</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 10, 'num...</td>\n",
       "      <td>0.714501</td>\n",
       "      <td>0.730560</td>\n",
       "      <td>0.730541</td>\n",
       "      <td>0.707999</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>39</td>\n",
       "      <td>0.793896</td>\n",
       "      <td>0.795366</td>\n",
       "      <td>0.800826</td>\n",
       "      <td>0.798770</td>\n",
       "      <td>0.797214</td>\n",
       "      <td>0.002733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.203555</td>\n",
       "      <td>0.115900</td>\n",
       "      <td>0.065891</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 10, 'num...</td>\n",
       "      <td>0.705910</td>\n",
       "      <td>0.717120</td>\n",
       "      <td>0.720680</td>\n",
       "      <td>0.699047</td>\n",
       "      <td>0.710689</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>44</td>\n",
       "      <td>0.817043</td>\n",
       "      <td>0.825145</td>\n",
       "      <td>0.830403</td>\n",
       "      <td>0.815741</td>\n",
       "      <td>0.822083</td>\n",
       "      <td>0.006005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.259698</td>\n",
       "      <td>0.034217</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 25, 'num...</td>\n",
       "      <td>0.728448</td>\n",
       "      <td>0.737943</td>\n",
       "      <td>0.731136</td>\n",
       "      <td>0.720770</td>\n",
       "      <td>0.729574</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>27</td>\n",
       "      <td>0.745415</td>\n",
       "      <td>0.742758</td>\n",
       "      <td>0.746462</td>\n",
       "      <td>0.743572</td>\n",
       "      <td>0.744552</td>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.421558</td>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.035094</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 25, 'num...</td>\n",
       "      <td>0.728572</td>\n",
       "      <td>0.738353</td>\n",
       "      <td>0.734705</td>\n",
       "      <td>0.726722</td>\n",
       "      <td>0.732088</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>19</td>\n",
       "      <td>0.761574</td>\n",
       "      <td>0.760410</td>\n",
       "      <td>0.762917</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.762093</td>\n",
       "      <td>0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.040651</td>\n",
       "      <td>0.047751</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 25, 'num...</td>\n",
       "      <td>0.721201</td>\n",
       "      <td>0.735090</td>\n",
       "      <td>0.728702</td>\n",
       "      <td>0.715255</td>\n",
       "      <td>0.725062</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>35</td>\n",
       "      <td>0.791048</td>\n",
       "      <td>0.791049</td>\n",
       "      <td>0.793778</td>\n",
       "      <td>0.792664</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.001156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.207578</td>\n",
       "      <td>0.046082</td>\n",
       "      <td>0.059548</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 25, 'num...</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.721802</td>\n",
       "      <td>0.719984</td>\n",
       "      <td>0.696095</td>\n",
       "      <td>0.709458</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>46</td>\n",
       "      <td>0.817462</td>\n",
       "      <td>0.822149</td>\n",
       "      <td>0.824530</td>\n",
       "      <td>0.816423</td>\n",
       "      <td>0.820141</td>\n",
       "      <td>0.003328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.228519</td>\n",
       "      <td>0.023733</td>\n",
       "      <td>0.032135</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 50, 'num...</td>\n",
       "      <td>0.728448</td>\n",
       "      <td>0.737943</td>\n",
       "      <td>0.731136</td>\n",
       "      <td>0.720770</td>\n",
       "      <td>0.729574</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>27</td>\n",
       "      <td>0.745415</td>\n",
       "      <td>0.742758</td>\n",
       "      <td>0.746462</td>\n",
       "      <td>0.743572</td>\n",
       "      <td>0.744552</td>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.390770</td>\n",
       "      <td>0.010866</td>\n",
       "      <td>0.036280</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 50, 'num...</td>\n",
       "      <td>0.728572</td>\n",
       "      <td>0.738353</td>\n",
       "      <td>0.734705</td>\n",
       "      <td>0.726722</td>\n",
       "      <td>0.732088</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>19</td>\n",
       "      <td>0.761574</td>\n",
       "      <td>0.760410</td>\n",
       "      <td>0.762917</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.762093</td>\n",
       "      <td>0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.861006</td>\n",
       "      <td>0.039058</td>\n",
       "      <td>0.051283</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 50, 'num...</td>\n",
       "      <td>0.721201</td>\n",
       "      <td>0.735090</td>\n",
       "      <td>0.728702</td>\n",
       "      <td>0.715255</td>\n",
       "      <td>0.725062</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>35</td>\n",
       "      <td>0.791048</td>\n",
       "      <td>0.791049</td>\n",
       "      <td>0.793778</td>\n",
       "      <td>0.792664</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.001156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.214397</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.057276</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 50, 'num...</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.721802</td>\n",
       "      <td>0.719984</td>\n",
       "      <td>0.696150</td>\n",
       "      <td>0.709471</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>45</td>\n",
       "      <td>0.817462</td>\n",
       "      <td>0.822149</td>\n",
       "      <td>0.824530</td>\n",
       "      <td>0.816432</td>\n",
       "      <td>0.820143</td>\n",
       "      <td>0.003325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.223817</td>\n",
       "      <td>0.034266</td>\n",
       "      <td>0.032476</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'num_l...</td>\n",
       "      <td>0.739413</td>\n",
       "      <td>0.745279</td>\n",
       "      <td>0.739311</td>\n",
       "      <td>0.735774</td>\n",
       "      <td>0.739944</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>8</td>\n",
       "      <td>0.759152</td>\n",
       "      <td>0.756765</td>\n",
       "      <td>0.759052</td>\n",
       "      <td>0.760003</td>\n",
       "      <td>0.758743</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.362874</td>\n",
       "      <td>0.076870</td>\n",
       "      <td>0.034101</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'num_l...</td>\n",
       "      <td>0.739553</td>\n",
       "      <td>0.745315</td>\n",
       "      <td>0.739212</td>\n",
       "      <td>0.735969</td>\n",
       "      <td>0.740012</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>4</td>\n",
       "      <td>0.759553</td>\n",
       "      <td>0.756820</td>\n",
       "      <td>0.759186</td>\n",
       "      <td>0.760184</td>\n",
       "      <td>0.758936</td>\n",
       "      <td>0.001272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.298371</td>\n",
       "      <td>0.043658</td>\n",
       "      <td>0.033890</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'num_l...</td>\n",
       "      <td>0.739553</td>\n",
       "      <td>0.745315</td>\n",
       "      <td>0.739212</td>\n",
       "      <td>0.735969</td>\n",
       "      <td>0.740012</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>4</td>\n",
       "      <td>0.759553</td>\n",
       "      <td>0.756820</td>\n",
       "      <td>0.759186</td>\n",
       "      <td>0.760184</td>\n",
       "      <td>0.758936</td>\n",
       "      <td>0.001272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.330146</td>\n",
       "      <td>0.116328</td>\n",
       "      <td>0.032465</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'num_l...</td>\n",
       "      <td>0.739553</td>\n",
       "      <td>0.745315</td>\n",
       "      <td>0.739212</td>\n",
       "      <td>0.735969</td>\n",
       "      <td>0.740012</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>4</td>\n",
       "      <td>0.759553</td>\n",
       "      <td>0.756820</td>\n",
       "      <td>0.759186</td>\n",
       "      <td>0.760184</td>\n",
       "      <td>0.758936</td>\n",
       "      <td>0.001272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.579669</td>\n",
       "      <td>0.044754</td>\n",
       "      <td>0.041490</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'num_...</td>\n",
       "      <td>0.740812</td>\n",
       "      <td>0.745855</td>\n",
       "      <td>0.738960</td>\n",
       "      <td>0.735458</td>\n",
       "      <td>0.740271</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>1</td>\n",
       "      <td>0.761528</td>\n",
       "      <td>0.759084</td>\n",
       "      <td>0.760102</td>\n",
       "      <td>0.761611</td>\n",
       "      <td>0.760581</td>\n",
       "      <td>0.001052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.767453</td>\n",
       "      <td>0.103936</td>\n",
       "      <td>0.045289</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'num_...</td>\n",
       "      <td>0.737928</td>\n",
       "      <td>0.742880</td>\n",
       "      <td>0.739408</td>\n",
       "      <td>0.734156</td>\n",
       "      <td>0.738593</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>14</td>\n",
       "      <td>0.793907</td>\n",
       "      <td>0.789865</td>\n",
       "      <td>0.790842</td>\n",
       "      <td>0.792641</td>\n",
       "      <td>0.791814</td>\n",
       "      <td>0.001566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.337136</td>\n",
       "      <td>0.454735</td>\n",
       "      <td>0.074790</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'num_...</td>\n",
       "      <td>0.728408</td>\n",
       "      <td>0.736296</td>\n",
       "      <td>0.733680</td>\n",
       "      <td>0.722891</td>\n",
       "      <td>0.730319</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>23</td>\n",
       "      <td>0.847210</td>\n",
       "      <td>0.843878</td>\n",
       "      <td>0.847737</td>\n",
       "      <td>0.848906</td>\n",
       "      <td>0.846933</td>\n",
       "      <td>0.001867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.350219</td>\n",
       "      <td>0.288461</td>\n",
       "      <td>0.071717</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'num_...</td>\n",
       "      <td>0.724429</td>\n",
       "      <td>0.731179</td>\n",
       "      <td>0.729231</td>\n",
       "      <td>0.717861</td>\n",
       "      <td>0.725675</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>34</td>\n",
       "      <td>0.870050</td>\n",
       "      <td>0.869045</td>\n",
       "      <td>0.867596</td>\n",
       "      <td>0.869893</td>\n",
       "      <td>0.869146</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.245040</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 25, 'num_...</td>\n",
       "      <td>0.740816</td>\n",
       "      <td>0.745855</td>\n",
       "      <td>0.738960</td>\n",
       "      <td>0.735137</td>\n",
       "      <td>0.740192</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>2</td>\n",
       "      <td>0.761580</td>\n",
       "      <td>0.759084</td>\n",
       "      <td>0.760102</td>\n",
       "      <td>0.761643</td>\n",
       "      <td>0.760602</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.419091</td>\n",
       "      <td>0.016689</td>\n",
       "      <td>0.044859</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 25, 'num_...</td>\n",
       "      <td>0.738998</td>\n",
       "      <td>0.743287</td>\n",
       "      <td>0.739298</td>\n",
       "      <td>0.733716</td>\n",
       "      <td>0.738825</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>12</td>\n",
       "      <td>0.795900</td>\n",
       "      <td>0.792262</td>\n",
       "      <td>0.791164</td>\n",
       "      <td>0.793141</td>\n",
       "      <td>0.793117</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.905769</td>\n",
       "      <td>0.023230</td>\n",
       "      <td>0.058897</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 25, 'num_...</td>\n",
       "      <td>0.730217</td>\n",
       "      <td>0.736114</td>\n",
       "      <td>0.732539</td>\n",
       "      <td>0.725837</td>\n",
       "      <td>0.731177</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>21</td>\n",
       "      <td>0.855282</td>\n",
       "      <td>0.850830</td>\n",
       "      <td>0.852992</td>\n",
       "      <td>0.857312</td>\n",
       "      <td>0.854104</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.307148</td>\n",
       "      <td>0.051739</td>\n",
       "      <td>0.068255</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 25, 'num_...</td>\n",
       "      <td>0.719473</td>\n",
       "      <td>0.728866</td>\n",
       "      <td>0.725646</td>\n",
       "      <td>0.717450</td>\n",
       "      <td>0.722859</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>38</td>\n",
       "      <td>0.894742</td>\n",
       "      <td>0.890572</td>\n",
       "      <td>0.892876</td>\n",
       "      <td>0.895838</td>\n",
       "      <td>0.893507</td>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.242564</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.030670</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 50, 'num_...</td>\n",
       "      <td>0.740816</td>\n",
       "      <td>0.745855</td>\n",
       "      <td>0.738960</td>\n",
       "      <td>0.735137</td>\n",
       "      <td>0.740192</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>2</td>\n",
       "      <td>0.761580</td>\n",
       "      <td>0.759084</td>\n",
       "      <td>0.760102</td>\n",
       "      <td>0.761643</td>\n",
       "      <td>0.760602</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.404253</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>0.044520</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 50, 'num_...</td>\n",
       "      <td>0.738998</td>\n",
       "      <td>0.743287</td>\n",
       "      <td>0.739298</td>\n",
       "      <td>0.733716</td>\n",
       "      <td>0.738825</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>12</td>\n",
       "      <td>0.795900</td>\n",
       "      <td>0.792262</td>\n",
       "      <td>0.791164</td>\n",
       "      <td>0.793141</td>\n",
       "      <td>0.793117</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.884308</td>\n",
       "      <td>0.032452</td>\n",
       "      <td>0.059974</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 50, 'num_...</td>\n",
       "      <td>0.730219</td>\n",
       "      <td>0.736262</td>\n",
       "      <td>0.732290</td>\n",
       "      <td>0.725837</td>\n",
       "      <td>0.731152</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>22</td>\n",
       "      <td>0.855284</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.853692</td>\n",
       "      <td>0.857312</td>\n",
       "      <td>0.854306</td>\n",
       "      <td>0.002330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.333854</td>\n",
       "      <td>0.050877</td>\n",
       "      <td>0.064495</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 50, 'num_...</td>\n",
       "      <td>0.720125</td>\n",
       "      <td>0.728911</td>\n",
       "      <td>0.725749</td>\n",
       "      <td>0.718828</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>37</td>\n",
       "      <td>0.894351</td>\n",
       "      <td>0.890258</td>\n",
       "      <td>0.893213</td>\n",
       "      <td>0.896292</td>\n",
       "      <td>0.893528</td>\n",
       "      <td>0.002186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.230957</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0.031361</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'num_le...</td>\n",
       "      <td>0.738861</td>\n",
       "      <td>0.744025</td>\n",
       "      <td>0.739944</td>\n",
       "      <td>0.737110</td>\n",
       "      <td>0.739985</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>7</td>\n",
       "      <td>0.802414</td>\n",
       "      <td>0.795529</td>\n",
       "      <td>0.797698</td>\n",
       "      <td>0.800920</td>\n",
       "      <td>0.799140</td>\n",
       "      <td>0.002693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.236492</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.029048</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'num_le...</td>\n",
       "      <td>0.739077</td>\n",
       "      <td>0.743777</td>\n",
       "      <td>0.740262</td>\n",
       "      <td>0.736119</td>\n",
       "      <td>0.739809</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>9</td>\n",
       "      <td>0.801423</td>\n",
       "      <td>0.797509</td>\n",
       "      <td>0.798263</td>\n",
       "      <td>0.801202</td>\n",
       "      <td>0.799599</td>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.237207</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.028966</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'num_le...</td>\n",
       "      <td>0.739077</td>\n",
       "      <td>0.743777</td>\n",
       "      <td>0.740262</td>\n",
       "      <td>0.736119</td>\n",
       "      <td>0.739809</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>9</td>\n",
       "      <td>0.801423</td>\n",
       "      <td>0.797509</td>\n",
       "      <td>0.798263</td>\n",
       "      <td>0.801202</td>\n",
       "      <td>0.799599</td>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.258103</td>\n",
       "      <td>0.026805</td>\n",
       "      <td>0.028269</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'num_le...</td>\n",
       "      <td>0.739077</td>\n",
       "      <td>0.743777</td>\n",
       "      <td>0.740262</td>\n",
       "      <td>0.736119</td>\n",
       "      <td>0.739809</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>9</td>\n",
       "      <td>0.801423</td>\n",
       "      <td>0.797509</td>\n",
       "      <td>0.798263</td>\n",
       "      <td>0.801202</td>\n",
       "      <td>0.799599</td>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.194088</td>\n",
       "      <td>0.026176</td>\n",
       "      <td>0.028783</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'num_l...</td>\n",
       "      <td>0.737592</td>\n",
       "      <td>0.742938</td>\n",
       "      <td>0.737533</td>\n",
       "      <td>0.733752</td>\n",
       "      <td>0.737954</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>17</td>\n",
       "      <td>0.828542</td>\n",
       "      <td>0.826033</td>\n",
       "      <td>0.825996</td>\n",
       "      <td>0.831866</td>\n",
       "      <td>0.828109</td>\n",
       "      <td>0.002402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.339416</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.050319</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'num_l...</td>\n",
       "      <td>0.727381</td>\n",
       "      <td>0.734392</td>\n",
       "      <td>0.724636</td>\n",
       "      <td>0.720724</td>\n",
       "      <td>0.726783</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>33</td>\n",
       "      <td>0.909871</td>\n",
       "      <td>0.913100</td>\n",
       "      <td>0.909307</td>\n",
       "      <td>0.920476</td>\n",
       "      <td>0.913188</td>\n",
       "      <td>0.004450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.721775</td>\n",
       "      <td>0.299984</td>\n",
       "      <td>0.069555</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'num_l...</td>\n",
       "      <td>0.719405</td>\n",
       "      <td>0.723145</td>\n",
       "      <td>0.721404</td>\n",
       "      <td>0.713229</td>\n",
       "      <td>0.719296</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>40</td>\n",
       "      <td>0.951878</td>\n",
       "      <td>0.953786</td>\n",
       "      <td>0.949213</td>\n",
       "      <td>0.951373</td>\n",
       "      <td>0.951563</td>\n",
       "      <td>0.001628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.605228</td>\n",
       "      <td>0.014820</td>\n",
       "      <td>0.058117</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'num_l...</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.723343</td>\n",
       "      <td>0.723039</td>\n",
       "      <td>0.710015</td>\n",
       "      <td>0.718077</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>41</td>\n",
       "      <td>0.956617</td>\n",
       "      <td>0.956978</td>\n",
       "      <td>0.957006</td>\n",
       "      <td>0.959988</td>\n",
       "      <td>0.957647</td>\n",
       "      <td>0.001360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.183641</td>\n",
       "      <td>0.011061</td>\n",
       "      <td>0.031571</td>\n",
       "      <td>0.003957</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 25, 'num_l...</td>\n",
       "      <td>0.737638</td>\n",
       "      <td>0.743312</td>\n",
       "      <td>0.738796</td>\n",
       "      <td>0.733311</td>\n",
       "      <td>0.738264</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>15</td>\n",
       "      <td>0.830738</td>\n",
       "      <td>0.830371</td>\n",
       "      <td>0.828900</td>\n",
       "      <td>0.831504</td>\n",
       "      <td>0.830378</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.358445</td>\n",
       "      <td>0.019295</td>\n",
       "      <td>0.041290</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 25, 'num_l...</td>\n",
       "      <td>0.725524</td>\n",
       "      <td>0.735499</td>\n",
       "      <td>0.726668</td>\n",
       "      <td>0.724446</td>\n",
       "      <td>0.728034</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>31</td>\n",
       "      <td>0.928711</td>\n",
       "      <td>0.930195</td>\n",
       "      <td>0.927708</td>\n",
       "      <td>0.926595</td>\n",
       "      <td>0.928302</td>\n",
       "      <td>0.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.789581</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>0.065995</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 25, 'num_l...</td>\n",
       "      <td>0.714447</td>\n",
       "      <td>0.716802</td>\n",
       "      <td>0.713350</td>\n",
       "      <td>0.709172</td>\n",
       "      <td>0.713443</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>42</td>\n",
       "      <td>0.992380</td>\n",
       "      <td>0.993108</td>\n",
       "      <td>0.992538</td>\n",
       "      <td>0.991267</td>\n",
       "      <td>0.992323</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.238442</td>\n",
       "      <td>0.033762</td>\n",
       "      <td>0.090204</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 25, 'num_l...</td>\n",
       "      <td>0.702081</td>\n",
       "      <td>0.710180</td>\n",
       "      <td>0.707295</td>\n",
       "      <td>0.694770</td>\n",
       "      <td>0.703581</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>48</td>\n",
       "      <td>0.999363</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.999556</td>\n",
       "      <td>0.999494</td>\n",
       "      <td>0.999446</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.200198</td>\n",
       "      <td>0.028470</td>\n",
       "      <td>0.031493</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 50, 'num_l...</td>\n",
       "      <td>0.737638</td>\n",
       "      <td>0.743312</td>\n",
       "      <td>0.738796</td>\n",
       "      <td>0.733311</td>\n",
       "      <td>0.738264</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>15</td>\n",
       "      <td>0.830738</td>\n",
       "      <td>0.830371</td>\n",
       "      <td>0.828900</td>\n",
       "      <td>0.831504</td>\n",
       "      <td>0.830378</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.367740</td>\n",
       "      <td>0.025999</td>\n",
       "      <td>0.040576</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 50, 'num_l...</td>\n",
       "      <td>0.727429</td>\n",
       "      <td>0.734365</td>\n",
       "      <td>0.727781</td>\n",
       "      <td>0.719806</td>\n",
       "      <td>0.727345</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>32</td>\n",
       "      <td>0.929114</td>\n",
       "      <td>0.931343</td>\n",
       "      <td>0.929197</td>\n",
       "      <td>0.928706</td>\n",
       "      <td>0.929590</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.908505</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.066995</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 50, 'num_l...</td>\n",
       "      <td>0.709557</td>\n",
       "      <td>0.718239</td>\n",
       "      <td>0.716021</td>\n",
       "      <td>0.709421</td>\n",
       "      <td>0.713309</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>43</td>\n",
       "      <td>0.991877</td>\n",
       "      <td>0.993156</td>\n",
       "      <td>0.993487</td>\n",
       "      <td>0.993353</td>\n",
       "      <td>0.992968</td>\n",
       "      <td>0.000641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.361639</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>0.088108</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 50, 'num_l...</td>\n",
       "      <td>0.704439</td>\n",
       "      <td>0.711877</td>\n",
       "      <td>0.713662</td>\n",
       "      <td>0.701677</td>\n",
       "      <td>0.707914</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>47</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.999247</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.193696      0.034194         0.031037        0.004777   \n",
       "1        0.171575      0.000472         0.025996        0.001089   \n",
       "2        0.194387      0.046441         0.025186        0.000691   \n",
       "3        0.173624      0.003959         0.026249        0.002779   \n",
       "4        0.303688      0.101949         0.033101        0.001785   \n",
       "5        0.452661      0.080206         0.034046        0.001220   \n",
       "6        1.037155      0.236703         0.060690        0.009822   \n",
       "7        1.203555      0.115900         0.065891        0.003921   \n",
       "8        0.259698      0.034217         0.031284        0.002852   \n",
       "9        0.421558      0.021289         0.035094        0.001862   \n",
       "10       0.814707      0.040651         0.047751        0.001270   \n",
       "11       1.207578      0.046082         0.059548        0.004680   \n",
       "12       0.228519      0.023733         0.032135        0.003234   \n",
       "13       0.390770      0.010866         0.036280        0.001327   \n",
       "14       0.861006      0.039058         0.051283        0.003608   \n",
       "15       1.214397      0.026439         0.057276        0.002946   \n",
       "16       0.223817      0.034266         0.032476        0.004266   \n",
       "17       0.362874      0.076870         0.034101        0.003396   \n",
       "18       0.298371      0.043658         0.033890        0.003622   \n",
       "19       0.330146      0.116328         0.032465        0.003449   \n",
       "20       0.579669      0.044754         0.041490        0.005008   \n",
       "21       0.767453      0.103936         0.045289        0.002021   \n",
       "22       1.337136      0.454735         0.074790        0.008833   \n",
       "23       1.350219      0.288461         0.071717        0.003742   \n",
       "24       0.245040      0.015316         0.033881        0.005985   \n",
       "25       0.419091      0.016689         0.044859        0.004992   \n",
       "26       0.905769      0.023230         0.058897        0.002274   \n",
       "27       1.307148      0.051739         0.068255        0.004616   \n",
       "28       0.242564      0.004020         0.030670        0.001553   \n",
       "29       0.404253      0.007325         0.044520        0.006353   \n",
       "30       0.884308      0.032452         0.059974        0.002581   \n",
       "31       1.333854      0.050877         0.064495        0.001009   \n",
       "32       0.230957      0.017629         0.031361        0.002319   \n",
       "33       0.236492      0.003207         0.029048        0.000872   \n",
       "34       0.237207      0.003344         0.028966        0.000966   \n",
       "35       0.258103      0.026805         0.028269        0.000916   \n",
       "36       0.194088      0.026176         0.028783        0.001152   \n",
       "37       0.339416      0.006946         0.050319        0.003728   \n",
       "38       0.721775      0.299984         0.069555        0.010288   \n",
       "39       0.605228      0.014820         0.058117        0.001006   \n",
       "40       0.183641      0.011061         0.031571        0.003957   \n",
       "41       0.358445      0.019295         0.041290        0.001217   \n",
       "42       0.789581      0.019287         0.065995        0.001632   \n",
       "43       1.238442      0.033762         0.090204        0.002400   \n",
       "44       0.200198      0.028470         0.031493        0.003107   \n",
       "45       0.367740      0.025999         0.040576        0.001898   \n",
       "46       0.908505      0.094828         0.066995        0.001122   \n",
       "47       1.361639      0.040034         0.088108        0.001557   \n",
       "\n",
       "   param_learning_rate param_max_depth param_num_leaves  \\\n",
       "0                0.001               5               31   \n",
       "1                0.001               5              100   \n",
       "2                0.001               5              300   \n",
       "3                0.001               5              500   \n",
       "4                0.001              10               31   \n",
       "5                0.001              10              100   \n",
       "6                0.001              10              300   \n",
       "7                0.001              10              500   \n",
       "8                0.001              25               31   \n",
       "9                0.001              25              100   \n",
       "10               0.001              25              300   \n",
       "11               0.001              25              500   \n",
       "12               0.001              50               31   \n",
       "13               0.001              50              100   \n",
       "14               0.001              50              300   \n",
       "15               0.001              50              500   \n",
       "16                0.01               5               31   \n",
       "17                0.01               5              100   \n",
       "18                0.01               5              300   \n",
       "19                0.01               5              500   \n",
       "20                0.01              10               31   \n",
       "21                0.01              10              100   \n",
       "22                0.01              10              300   \n",
       "23                0.01              10              500   \n",
       "24                0.01              25               31   \n",
       "25                0.01              25              100   \n",
       "26                0.01              25              300   \n",
       "27                0.01              25              500   \n",
       "28                0.01              50               31   \n",
       "29                0.01              50              100   \n",
       "30                0.01              50              300   \n",
       "31                0.01              50              500   \n",
       "32                 0.1               5               31   \n",
       "33                 0.1               5              100   \n",
       "34                 0.1               5              300   \n",
       "35                 0.1               5              500   \n",
       "36                 0.1              10               31   \n",
       "37                 0.1              10              100   \n",
       "38                 0.1              10              300   \n",
       "39                 0.1              10              500   \n",
       "40                 0.1              25               31   \n",
       "41                 0.1              25              100   \n",
       "42                 0.1              25              300   \n",
       "43                 0.1              25              500   \n",
       "44                 0.1              50               31   \n",
       "45                 0.1              50              100   \n",
       "46                 0.1              50              300   \n",
       "47                 0.1              50              500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.001, 'max_depth': 5, 'num_...           0.726286   \n",
       "1   {'learning_rate': 0.001, 'max_depth': 5, 'num_...           0.726790   \n",
       "2   {'learning_rate': 0.001, 'max_depth': 5, 'num_...           0.726790   \n",
       "3   {'learning_rate': 0.001, 'max_depth': 5, 'num_...           0.726790   \n",
       "4   {'learning_rate': 0.001, 'max_depth': 10, 'num...           0.728448   \n",
       "5   {'learning_rate': 0.001, 'max_depth': 10, 'num...           0.728878   \n",
       "6   {'learning_rate': 0.001, 'max_depth': 10, 'num...           0.714501   \n",
       "7   {'learning_rate': 0.001, 'max_depth': 10, 'num...           0.705910   \n",
       "8   {'learning_rate': 0.001, 'max_depth': 25, 'num...           0.728448   \n",
       "9   {'learning_rate': 0.001, 'max_depth': 25, 'num...           0.728572   \n",
       "10  {'learning_rate': 0.001, 'max_depth': 25, 'num...           0.721201   \n",
       "11  {'learning_rate': 0.001, 'max_depth': 25, 'num...           0.699949   \n",
       "12  {'learning_rate': 0.001, 'max_depth': 50, 'num...           0.728448   \n",
       "13  {'learning_rate': 0.001, 'max_depth': 50, 'num...           0.728572   \n",
       "14  {'learning_rate': 0.001, 'max_depth': 50, 'num...           0.721201   \n",
       "15  {'learning_rate': 0.001, 'max_depth': 50, 'num...           0.699949   \n",
       "16  {'learning_rate': 0.01, 'max_depth': 5, 'num_l...           0.739413   \n",
       "17  {'learning_rate': 0.01, 'max_depth': 5, 'num_l...           0.739553   \n",
       "18  {'learning_rate': 0.01, 'max_depth': 5, 'num_l...           0.739553   \n",
       "19  {'learning_rate': 0.01, 'max_depth': 5, 'num_l...           0.739553   \n",
       "20  {'learning_rate': 0.01, 'max_depth': 10, 'num_...           0.740812   \n",
       "21  {'learning_rate': 0.01, 'max_depth': 10, 'num_...           0.737928   \n",
       "22  {'learning_rate': 0.01, 'max_depth': 10, 'num_...           0.728408   \n",
       "23  {'learning_rate': 0.01, 'max_depth': 10, 'num_...           0.724429   \n",
       "24  {'learning_rate': 0.01, 'max_depth': 25, 'num_...           0.740816   \n",
       "25  {'learning_rate': 0.01, 'max_depth': 25, 'num_...           0.738998   \n",
       "26  {'learning_rate': 0.01, 'max_depth': 25, 'num_...           0.730217   \n",
       "27  {'learning_rate': 0.01, 'max_depth': 25, 'num_...           0.719473   \n",
       "28  {'learning_rate': 0.01, 'max_depth': 50, 'num_...           0.740816   \n",
       "29  {'learning_rate': 0.01, 'max_depth': 50, 'num_...           0.738998   \n",
       "30  {'learning_rate': 0.01, 'max_depth': 50, 'num_...           0.730219   \n",
       "31  {'learning_rate': 0.01, 'max_depth': 50, 'num_...           0.720125   \n",
       "32  {'learning_rate': 0.1, 'max_depth': 5, 'num_le...           0.738861   \n",
       "33  {'learning_rate': 0.1, 'max_depth': 5, 'num_le...           0.739077   \n",
       "34  {'learning_rate': 0.1, 'max_depth': 5, 'num_le...           0.739077   \n",
       "35  {'learning_rate': 0.1, 'max_depth': 5, 'num_le...           0.739077   \n",
       "36  {'learning_rate': 0.1, 'max_depth': 10, 'num_l...           0.737592   \n",
       "37  {'learning_rate': 0.1, 'max_depth': 10, 'num_l...           0.727381   \n",
       "38  {'learning_rate': 0.1, 'max_depth': 10, 'num_l...           0.719405   \n",
       "39  {'learning_rate': 0.1, 'max_depth': 10, 'num_l...           0.715909   \n",
       "40  {'learning_rate': 0.1, 'max_depth': 25, 'num_l...           0.737638   \n",
       "41  {'learning_rate': 0.1, 'max_depth': 25, 'num_l...           0.725524   \n",
       "42  {'learning_rate': 0.1, 'max_depth': 25, 'num_l...           0.714447   \n",
       "43  {'learning_rate': 0.1, 'max_depth': 25, 'num_l...           0.702081   \n",
       "44  {'learning_rate': 0.1, 'max_depth': 50, 'num_l...           0.737638   \n",
       "45  {'learning_rate': 0.1, 'max_depth': 50, 'num_l...           0.727429   \n",
       "46  {'learning_rate': 0.1, 'max_depth': 50, 'num_l...           0.709557   \n",
       "47  {'learning_rate': 0.1, 'max_depth': 50, 'num_l...           0.704439   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0            0.737935           0.731483           0.721501         0.729302   \n",
       "1            0.738576           0.731976           0.722803         0.730036   \n",
       "2            0.738576           0.731976           0.722803         0.730036   \n",
       "3            0.738576           0.731976           0.722803         0.730036   \n",
       "4            0.737943           0.731136           0.720770         0.729574   \n",
       "5            0.738260           0.734723           0.726689         0.732138   \n",
       "6            0.730560           0.730541           0.707999         0.720900   \n",
       "7            0.717120           0.720680           0.699047         0.710689   \n",
       "8            0.737943           0.731136           0.720770         0.729574   \n",
       "9            0.738353           0.734705           0.726722         0.732088   \n",
       "10           0.735090           0.728702           0.715255         0.725062   \n",
       "11           0.721802           0.719984           0.696095         0.709458   \n",
       "12           0.737943           0.731136           0.720770         0.729574   \n",
       "13           0.738353           0.734705           0.726722         0.732088   \n",
       "14           0.735090           0.728702           0.715255         0.725062   \n",
       "15           0.721802           0.719984           0.696150         0.709471   \n",
       "16           0.745279           0.739311           0.735774         0.739944   \n",
       "17           0.745315           0.739212           0.735969         0.740012   \n",
       "18           0.745315           0.739212           0.735969         0.740012   \n",
       "19           0.745315           0.739212           0.735969         0.740012   \n",
       "20           0.745855           0.738960           0.735458         0.740271   \n",
       "21           0.742880           0.739408           0.734156         0.738593   \n",
       "22           0.736296           0.733680           0.722891         0.730319   \n",
       "23           0.731179           0.729231           0.717861         0.725675   \n",
       "24           0.745855           0.738960           0.735137         0.740192   \n",
       "25           0.743287           0.739298           0.733716         0.738825   \n",
       "26           0.736114           0.732539           0.725837         0.731177   \n",
       "27           0.728866           0.725646           0.717450         0.722859   \n",
       "28           0.745855           0.738960           0.735137         0.740192   \n",
       "29           0.743287           0.739298           0.733716         0.738825   \n",
       "30           0.736262           0.732290           0.725837         0.731152   \n",
       "31           0.728911           0.725749           0.718828         0.723404   \n",
       "32           0.744025           0.739944           0.737110         0.739985   \n",
       "33           0.743777           0.740262           0.736119         0.739809   \n",
       "34           0.743777           0.740262           0.736119         0.739809   \n",
       "35           0.743777           0.740262           0.736119         0.739809   \n",
       "36           0.742938           0.737533           0.733752         0.737954   \n",
       "37           0.734392           0.724636           0.720724         0.726783   \n",
       "38           0.723145           0.721404           0.713229         0.719296   \n",
       "39           0.723343           0.723039           0.710015         0.718077   \n",
       "40           0.743312           0.738796           0.733311         0.738264   \n",
       "41           0.735499           0.726668           0.724446         0.728034   \n",
       "42           0.716802           0.713350           0.709172         0.713443   \n",
       "43           0.710180           0.707295           0.694770         0.703581   \n",
       "44           0.743312           0.738796           0.733311         0.738264   \n",
       "45           0.734365           0.727781           0.719806         0.727345   \n",
       "46           0.718239           0.716021           0.709421         0.713309   \n",
       "47           0.711877           0.713662           0.701677         0.707914   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.006108               30            0.743600            0.743121   \n",
       "1         0.005906               24            0.743705            0.743319   \n",
       "2         0.005906               24            0.743705            0.743319   \n",
       "3         0.005906               24            0.743705            0.743319   \n",
       "4         0.006149               27            0.745415            0.742758   \n",
       "5         0.004596               18            0.761843            0.760675   \n",
       "6         0.009920               39            0.793896            0.795366   \n",
       "7         0.008654               44            0.817043            0.825145   \n",
       "8         0.006149               27            0.745415            0.742758   \n",
       "9         0.004670               19            0.761574            0.760410   \n",
       "10        0.007498               35            0.791048            0.791049   \n",
       "11        0.011534               46            0.817462            0.822149   \n",
       "12        0.006149               27            0.745415            0.742758   \n",
       "13        0.004670               19            0.761574            0.760410   \n",
       "14        0.007498               35            0.791048            0.791049   \n",
       "15        0.011518               45            0.817462            0.822149   \n",
       "16        0.003411                8            0.759152            0.756765   \n",
       "17        0.003366                4            0.759553            0.756820   \n",
       "18        0.003366                4            0.759553            0.756820   \n",
       "19        0.003366                4            0.759553            0.756820   \n",
       "20        0.003753                1            0.761528            0.759084   \n",
       "21        0.003129               14            0.793907            0.789865   \n",
       "22        0.005144               23            0.847210            0.843878   \n",
       "23        0.005137               34            0.870050            0.869045   \n",
       "24        0.003858                2            0.761580            0.759084   \n",
       "25        0.003401               12            0.795900            0.792262   \n",
       "26        0.003731               21            0.855282            0.850830   \n",
       "27        0.004598               38            0.894742            0.890572   \n",
       "28        0.003858                2            0.761580            0.759084   \n",
       "29        0.003401               12            0.795900            0.792262   \n",
       "30        0.003759               22            0.855284            0.850937   \n",
       "31        0.004108               37            0.894351            0.890258   \n",
       "32        0.002542                7            0.802414            0.795529   \n",
       "33        0.002743                9            0.801423            0.797509   \n",
       "34        0.002743                9            0.801423            0.797509   \n",
       "35        0.002743                9            0.801423            0.797509   \n",
       "36        0.003271               17            0.828542            0.826033   \n",
       "37        0.004989               33            0.909871            0.913100   \n",
       "38        0.003744               40            0.951878            0.953786   \n",
       "39        0.005524               41            0.956617            0.956978   \n",
       "40        0.003560               15            0.830738            0.830371   \n",
       "41        0.004381               31            0.928711            0.930195   \n",
       "42        0.002763               42            0.992380            0.993108   \n",
       "43        0.005857               48            0.999363            0.999374   \n",
       "44        0.003560               15            0.830738            0.830371   \n",
       "45        0.005155               32            0.929114            0.931343   \n",
       "46        0.003900               43            0.991877            0.993156   \n",
       "47        0.004993               47            0.999395            0.999490   \n",
       "\n",
       "    split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0             0.746197            0.745486          0.744601         0.001277  \n",
       "1             0.746628            0.747018          0.745167         0.001667  \n",
       "2             0.746628            0.747018          0.745167         0.001667  \n",
       "3             0.746628            0.747018          0.745167         0.001667  \n",
       "4             0.746462            0.743572          0.744552         0.001464  \n",
       "5             0.763184            0.764658          0.762590         0.001488  \n",
       "6             0.800826            0.798770          0.797214         0.002733  \n",
       "7             0.830403            0.815741          0.822083         0.006005  \n",
       "8             0.746462            0.743572          0.744552         0.001464  \n",
       "9             0.762917            0.763469          0.762093         0.001191  \n",
       "10            0.793778            0.792664          0.792135         0.001156  \n",
       "11            0.824530            0.816423          0.820141         0.003328  \n",
       "12            0.746462            0.743572          0.744552         0.001464  \n",
       "13            0.762917            0.763469          0.762093         0.001191  \n",
       "14            0.793778            0.792664          0.792135         0.001156  \n",
       "15            0.824530            0.816432          0.820143         0.003325  \n",
       "16            0.759052            0.760003          0.758743         0.001200  \n",
       "17            0.759186            0.760184          0.758936         0.001272  \n",
       "18            0.759186            0.760184          0.758936         0.001272  \n",
       "19            0.759186            0.760184          0.758936         0.001272  \n",
       "20            0.760102            0.761611          0.760581         0.001052  \n",
       "21            0.790842            0.792641          0.791814         0.001566  \n",
       "22            0.847737            0.848906          0.846933         0.001867  \n",
       "23            0.867596            0.869893          0.869146         0.000973  \n",
       "24            0.760102            0.761643          0.760602         0.001072  \n",
       "25            0.791164            0.793141          0.793117         0.001753  \n",
       "26            0.852992            0.857312          0.854104         0.002431  \n",
       "27            0.892876            0.895838          0.893507         0.001998  \n",
       "28            0.760102            0.761643          0.760602         0.001072  \n",
       "29            0.791164            0.793141          0.793117         0.001753  \n",
       "30            0.853692            0.857312          0.854306         0.002330  \n",
       "31            0.893213            0.896292          0.893528         0.002186  \n",
       "32            0.797698            0.800920          0.799140         0.002693  \n",
       "33            0.798263            0.801202          0.799599         0.001736  \n",
       "34            0.798263            0.801202          0.799599         0.001736  \n",
       "35            0.798263            0.801202          0.799599         0.001736  \n",
       "36            0.825996            0.831866          0.828109         0.002402  \n",
       "37            0.909307            0.920476          0.913188         0.004450  \n",
       "38            0.949213            0.951373          0.951563         0.001628  \n",
       "39            0.957006            0.959988          0.957647         0.001360  \n",
       "40            0.828900            0.831504          0.830378         0.000946  \n",
       "41            0.927708            0.926595          0.928302         0.001325  \n",
       "42            0.992538            0.991267          0.992323         0.000667  \n",
       "43            0.999556            0.999494          0.999446         0.000081  \n",
       "44            0.828900            0.831504          0.830378         0.000946  \n",
       "45            0.929197            0.928706          0.929590         0.001029  \n",
       "46            0.993487            0.993353          0.992968         0.000641  \n",
       "47            0.999400            0.999247          0.999383         0.000087  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2_result = pd.DataFrame.from_dict(grid_result.cv_results_) #詳細表示\n",
    "gs2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7398896671418831"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valデータで最も良かったモデルで評価。スコアを表示\n",
    "\n",
    "X_test_scalered = sscaler.transform(x_test)\n",
    "\n",
    "best_grid_result = grid_result.best_estimator_\n",
    "predicted_label = best_grid_result.predict_proba(X_test_scalered)\n",
    "score = roc_auc_score(y_test,predicted_label[:,1])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グリッドサーチで'learning_rate': 0.01, 'max_depth': 10, 'num_leaves': 31のときにスコアが高いことがわかり、valデータでの結果はAUC:0.739で0.744より少し下がったが同程度となった。そのため今回はこのモデルでカグルに提出する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】最終的なモデルの選定\n",
    "最終的にこれは良いというモデルを選び、推定した結果をKaggleに提出してスコアを確認してください。どういったアイデアを取り入れ、どの程度のスコアになったかを記載してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SK_ID_CURR    TARGET\n",
      "0          100001  0.056408\n",
      "1          100005  0.084480\n",
      "2          100013  0.041785\n",
      "3          100028  0.058298\n",
      "4          100038  0.093995\n",
      "...           ...       ...\n",
      "48739      456221  0.041785\n",
      "48740      456222  0.041093\n",
      "48741      456223  0.058220\n",
      "48742      456224  0.068241\n",
      "48743      456250  0.086987\n",
      "\n",
      "[48744 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"application_test.csv\")\n",
    "test_data_1 = test_data[[\"DAYS_BIRTH\",\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]]\n",
    "\n",
    "#標準化\n",
    "sscaler = StandardScaler()\n",
    "sscaler.fit(x_train)\n",
    "test_data_scalerd = sscaler.transform(test_data_1)\n",
    "\n",
    "#最後のモデルで確率予測を返す\n",
    "best_grid_result = grid_result.best_estimator_\n",
    "predicted_label_gbm_2 = best_grid_result.predict_proba(test_data_scalerd)\n",
    "\n",
    "#提出用のデータ型に変換\n",
    "test_result_2 = np.hstack((test_data[\"SK_ID_CURR\"].values.reshape(-1,1),predicted_label_gbm_2[:,1].reshape(-1,1)))\n",
    "\n",
    "test_result_2 = pd.DataFrame(test_result_2,columns=[\"SK_ID_CURR\",\"TARGET\"])\n",
    "\n",
    "test_result_2[\"SK_ID_CURR\"] = test_result_2[\"SK_ID_CURR\"].astype(int)\n",
    "\n",
    "print(test_result_2)\n",
    "\n",
    "#提出ファイルを作成\n",
    "test_result_2.to_csv('Home Credit Default Risk_submission3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提出スコア：0.69775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score of val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>randomforest with cross val</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>randomforest with grid search</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lightgbm with earlystop</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lightgbm with grid seach</td>\n",
       "      <td>0.739 (kaggle 0.697)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   AUC score of val\n",
       "randomforest with cross val                   0.685\n",
       "randomforest with grid search                 0.723\n",
       "xgboost                                       0.741\n",
       "lightgbm                                      0.742\n",
       "lightgbm with earlystop                       0.744\n",
       "lightgbm with grid seach       0.739 (kaggle 0.697)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果をまとめる\n",
    "pd.DataFrame({\"AUC score of val\":[\"0.685\",\"0.723\",\"0.741\",\"0.742\",\"0.744\",\"0.739 (kaggle 0.697)\"]},index=[\"randomforest with cross val\",\"randomforest with grid search\",\"xgboost\",\"lightgbm\",\"lightgbm with earlystop\",\"lightgbm with grid seach\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ※以降は自主学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### lightgbでのoptuna\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X_scalered, y, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dtest = lgb.Dataset(test_x, label=test_y)\n",
    " \n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 50, 120),\n",
    "    }\n",
    " \n",
    "    gbm2 = lgb.train(param, dtrain,valid_sets=dtest)\n",
    "    pred_label_2 = gbm2.predict(test_x)\n",
    "    score = roc_auc_score(y,pred_label_2[:,1])\n",
    "    return score\n",
    "\n",
    " \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    " \n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量重要度を表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns_0 DAYS_BIRTH\n",
      "Columns_1 EXT_SOURCE_1\n",
      "Columns_2 EXT_SOURCE_2\n",
      "Columns_3 EXT_SOURCE_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a274aea10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lightgbmの特徴量重要度をグラフ化する。lgb.plot_importance（学習したモデル）を使用\n",
    "\n",
    "Columns = [\"Columns_0\",\"Columns_1\",\"Columns_2\",\"Columns_3\"]\n",
    "Feature_dicted = dict(zip(Columns,tr_X.columns))\n",
    "for i,j in Feature_dicted.items():\n",
    "    print(i,j)\n",
    "lgb.plot_importance(gbm, height=0.5, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徴量重要度から、このモデルにおいて　EXT_SOURCE_2、EXT_SOURCE_3、EXT_SOURCE_1、DAYS_BIRTH　の順で重要な特徴量であることが分かった。なお、特徴量重要度は「そのアルゴリズムにおいて」予測に重要だった特徴量を高く評価し、\n",
    "絶対的な重要度を示す数値でないことに注意する必要がある。\n",
    "（ex.ランダムフォレストで評価した以下結果はEXT_SOURCE_1、EXT_SOURCE_3、EXT_SOURCE_2、DAYS_BIRTH　の順で重要な特徴量であった）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ランダムフォレストの特徴量重要度（グリッドサーチで最も精度が高かったパラメータ使用時）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 先ほど精度の最も良かったモデル（ランダムフォレスト）の特徴量の重要度を表示\n",
    "imp_df = pd.DataFrame()\n",
    "imp_df[\"feature\"] = X.columns\n",
    "imp_df[\"importance\"] = best_clf.feature_importances_\n",
    "imp_df = imp_df.sort_values(\"importance\")\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(imp_df.feature, imp_df.importance)\n",
    "plt.xlabel(\"Feature Importance of Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboostの特徴量重要度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f3': 11228.499600407808,\n",
       " 'f2': 8150.925577257403,\n",
       " 'f1': 9607.264909852483,\n",
       " 'f0': 4197.515972571406}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデル.get_score(importance_type='total_gain') でスコアを取得可能。この関数はxgboostのみ\n",
    "gain_score_xgb = bst.get_score(importance_type='total_gain')\n",
    "gain_score_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0 4197.515972571406\n",
      "f2 8150.925577257403\n",
      "f1 9607.264909852483\n",
      "f3 11228.499600407808\n"
     ]
    }
   ],
   "source": [
    "#降順にソートして出力\n",
    "fscore_xgb_1 = sorted([[k,v] for k,v in gain_score_xgb.items()], key=lambda x:x[1]) #1列目を元に昇順し、リストで返している。\n",
    "for l,o in fscore_xgb_1:\n",
    "    print(l,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0 DAYS_BIRTH\n",
      "f1 EXT_SOURCE_1\n",
      "f2 EXT_SOURCE_2\n",
      "f3 EXT_SOURCE_3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAFzCAYAAAB7K9PwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAVB0lEQVR4nO3de7RmZX0f8O9PRkBEB7mYUjCOWFMXKYpkWjElBjQ1IF2BNmbpKiuCSaSGrtq0TSxpUmubG6m9pJRESkwkGur9EpRoatVIrQEZDAIGLwRJBEkUL6NcliI+/WPvYc4MczkH5v3NzJnPZ629zt7Pu9/9PPs5+5zv2fvdZz81xggAsHiP2N0NAIB9hdAFgCZCFwCaCF0AaCJ0AaCJ0AWAJmsWXcHhhx8+1q1bt+hqAGCPce211945xjhi6/KFh+66deuyYcOGRVcDAHuMqvqLbZW7vAwATYQuADQRugDQROgCQBOhCwBNhC4ANBG6ANBE6AJAE6ELAE2ELgA0EboA0EToAkCThQ94cMPtG7Pu/CsWXQ0ArNitF5zeWp8zXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZCFwCaCF0AaCJ0AaCJ0AWAJkIXAJoIXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZCFwCaCF0AaCJ0AaCJ0AWAJkIXAJoIXQBoInQBoInQBYAmywrdqnp5Vd1UVV+tquur6rqq2lBVJy26gQCwWqxZ5nrnJTktyZeS3D3GGFX1tCRvSfLURTUOAFaTnZ7pVtXFSY5JcnmSl44xxvzSo5OM7b4RANjCTs90xxgvq6pTk5wyxrizqv5Rkl9L8vgkpy+6gQCwWqz4RqoxxjvHGE9NcmaSX9rWOlV17vyZ74b779n4cNsIAKvCQ757eYxxZZInV9Xh23jtkjHG+jHG+v0OWvuwGggAq8WKQreq/lZV1Tx/QpL9k3x5EQ0DgNVmuXcvb/KjSV5cVfcluTfJC5fcWAUA7MCyQneMsW6e/fV5AgBWyBOpAKCJ0AWAJkIXAJoIXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZCFwCaCF0AaCJ0AaCJ0AWAJkIXAJoIXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZCFwCaCF0AaCJ0AaCJ0AWAJmsWXcFxR63NhgtOX3Q1ALDHc6YLAE2ELgA0EboA0EToAkAToQsATYQuADQRugDQROgCQBOhCwBNhC4ANBG6ANBE6AJAE6ELAE2ELgA0WfjQfjfcvjHrzr9i0dUA8DDdahjWhXOmCwBNhC4ANBG6ANBE6AJAE6ELAE2ELgA0EboA0EToAkAToQsATYQuADQRugDQROgCQBOhCwBNhC4ANBG6ANBE6AJAE6ELAE2ELgA0EboA0EToAkAToQsATYQuADQRugDQROgCQBOhCwBNhC4ANBG6ANBkp6FbVS+vqpuq6u1V9SdV9c2q+tmOxgHAarJmGeucl+S0JHcneWKSMxfaIgBYpXZ4pltVFyc5JsnlSc4aY1yT5L6OhgHAarPDM90xxsuq6tQkp4wx7mxqEwCsSgu5kaqqzq2qDVW14f57Ni6iCgDY6ywkdMcYl4wx1o8x1u930NpFVAEAex3/MgQATZZz93KSpKr+RpINSR6b5DtV9TNJjh1jfH1RjQOA1WSnoTvGWLdk8ejFNQUAVjeXlwGgidAFgCZCFwCaCF0AaCJ0AaCJ0AWAJkIXAJoIXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZCFwCaCF0AaCJ0AaCJ0AWAJkIXAJoIXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZrFl3BcUetzYYLTl90NQCwx3OmCwBNhC4ANBG6ANBE6AJAE6ELAE2ELgA0EboA0EToAkAToQsATYQuADQRugDQROgCQBOhCwBNhC4ANBG6ANBk4ePp3nD7xqw7/4pFVwPQ4lbjg/MwONMFgCZCFwCaCF0AaCJ0AaCJ0AWAJkIXAJoIXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZCFwCaCF0AaCJ0AaCJ0AWAJkIXAJoIXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZCFwCa7DR0q+rlVXVTVY2qun6ePlpVT+9oIACsFmuWsc55SU5LcmSSm8YYX62q05JckuSZi2wcAKwmOzzTraqLkxyT5PIkzxxjfHV+6aokRy+4bQCwquzwTHeM8bKqOjXJKWOMO5e89JNJ3rvQlgHAKrOcy8tbqKpTMoXuSTtY59wk5ybJfo894iE3DgBWkxXdvVxVT0vy2iRnjDG+vL31xhiXjDHWjzHW73fQ2ofbRgBYFZYdulX13UnekeTHxxifWVyTAGB1Wsnl5VcmOSzJb1VVknx7jLF+Ia0CgFVop6E7xlg3z/7UPAEAD4EnUgFAE6ELAE2ELgA0EboA0EToAkAToQsATYQuADQRugDQROgCQBOhCwBNhC4ANBG6ANBE6AJAE6ELAE2ELgA0EboA0EToAkAToQsATYQuADQRugDQROgCQBOhCwBNhC4ANBG6ANBE6AJAE6ELAE3WLLqC445amw0XnL7oagBgj+dMFwCaCF0AaCJ0AaCJ0AWAJkIXAJoIXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZCFwCaCF0AaCJ0AaDJwsfTveH2jVl3/hWLrgYe5FbjOAN7GGe6ANBE6AJAE6ELAE2ELgA0EboA0EToAkAToQsATYQuADQRugDQROgCQBOhCwBNhC4ANBG6ANBE6AJAE6ELAE2ELgA0EboA0EToAkAToQsATYQuADQRugDQROgCQBOhCwBNhC4ANBG6ANBE6AJAk2WFblW9vKpuqqrLqurCqrq5qq6vqhMW3UAAWC2We6Z7XpLnJ7ksyVPm6dwkr1lQuwBg1VmzsxWq6uIkxyS5PMn3JDlnjDGSXFVVh1TVkWOMOxbcTgDY6+30THeM8bIkX0hySpL3J/n8kpdvS3LUYpoGAKvLSm+kqm2UjQetVHVuVW2oqg3337PxobUMAFaZlYbubUmesGT56ExnwVsYY1wyxlg/xli/30FrH077AGDVWGnoXp7kxTU5MclGn+cCwPLs9EaqrfxhpruYb05yT5KX7PIWAcAqtazQHWOsW7L4zxbTFABY3TyRCgCaCF0AaCJ0AaCJ0AWAJkIXAJoIXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZCFwCaCF0AaCJ0AaCJ0AWAJkIXAJoIXQBoInQBoInQBYAmQhcAmghdAGgidAGgidAFgCZCFwCaCF0AaLJm0RUcd9TabLjg9EVXAwB7PGe6ANBE6AJAE6ELAE2ELgA0EboA0EToAkAToQsATYQuADQRugDQROgCQBOhCwBNhC4ANBG6ANBE6AJAkxpjLLaCqm8k+fRCK1ldDk9y5+5uxF5Efy2fvloZ/bUy+mtLTxxjHLF14cLH003y6THG+oZ6VoWq2qC/lk9/LZ++Whn9tTL6a3lcXgaAJkIXAJp0hO4lDXWsJvprZfTX8umrldFfK6O/lmHhN1IBABOXlwGgyUJDt6pOrapPV9XNVXX+IuvaU1XVE6rqQ1V1U1V9sqr+xVx+aFW9v6o+O3993FxeVXXh3GfXV9UJS7Z19rz+Z6vq7N21Tx2qar+q+tOqes+8/KSqunre9zdX1f5z+QHz8s3z6+uWbOPn5/JPV9UP7549WbyqOqSq3lZVn5qPs2c5vratqv7l/HN4Y1W9saoOdGxtVlW/W1VfrKobl5TtsmOpqr6vqm6Y33NhVVXvHu4BxhgLmZLsl+TPkxyTZP8kn0hy7KLq21OnJEcmOWGef0ySzyQ5Nsl/SnL+XH5+kl+f55+f5L1JKsmJSa6eyw9Ncsv89XHz/ON29/4tsN/+VZL/leQ98/Jbkrxonr84yU/P8+cluXief1GSN8/zx87H3AFJnjQfi/vt7v1aUF/9XpKfmuf3T3KI42ub/XRUks8ledSSY+ocx9YWffTsJCckuXFJ2S47lpJ8LMmz5ve8N8lpu3ufu6dFnun+vSQ3jzFuGWN8K8mbkpyxwPr2SGOMO8YYH5/nv5Hkpkw//Gdk+mWZ+euZ8/wZSV4/JlclOaSqjkzyw0neP8b4yhjjq0nen+TUxl1pU1VHJzk9yWvn5UrynCRvm1fZur829ePbkjx3Xv+MJG8aY3xzjPG5JDdnOiZXlap6bKZflL+TJGOMb40xvhbH1/asSfKoqlqT5KAkd8Sx9YAxxpVJvrJV8S45lubXHjvG+JMxJfDrl2xrn7HI0D0qyeeXLN82l+2z5stTz0hydZLvGmPckUzBnOTx82rb67d9qT9/I8krknxnXj4sydfGGN+el5fu+wP9Mr++cV5/X+mvY5J8Kcnr5svxr62qR8fx9SBjjNuT/Ockf5kpbDcmuTaOrZ3ZVcfSUfP81uX7lEWG7rau1e+zt0pX1cFJ3p7kZ8YYX9/RqtsoGzsoX1Wq6h8m+eIY49qlxdtYdezktX2ivzKduZ2Q5DVjjGckuTvTJcDt2Wf7a/4s8oxMl4T/ZpJHJzltG6s6tpZnpf2j37LY0L0tyROWLB+d5AsLrG+PVVWPzBS4l40x3jEX//V8uSXz1y/O5dvrt32lP/9+kh+pqlszfSTxnExnvofMlwSTLff9gX6ZX1+b6fLYvtJftyW5bYxx9bz8tkwh7Ph6sB9K8rkxxpfGGPcleUeS749ja2d21bF02zy/dfk+ZZGhe02Sp8x3Bu6f6UaEyxdY3x5p/gzod5LcNMb4r0teujzJprv6zk7yB0vKXzzfGXhiko3zJZ0/SvK8qnrc/Bf78+ayVWWM8fNjjKPHGOsyHTMfHGOcleRDSV4wr7Z1f23qxxfM64+5/EXzHahPSvKUTDdxrCpjjL9K8vmq+ttz0XOT/FkcX9vyl0lOrKqD5p/LTX3l2NqxXXIsza99o6pOnPv/xUu2te9Y5F1ame5u+0ymu/t+YXffNbY7piQnZbqEcn2S6+bp+Zk+G/pAks/OXw+d168kvzn32Q1J1i/Z1k9kumnj5iQv2d371tB3J2fz3cvHZPrFdnOStyY5YC4/cF6+eX79mCXv/4W5Hz+dVXyXZJLjk2yYj7F3Zbpj1PG17b76D0k+leTGJG/IdAeyY2vzfr0x0+fd92U6M/3JXXksJVk/9/2fJ7ko8wOa9qXJE6kAoIknUgFAE6ELAE2ELgA0EboA0EToAkATocteo6rur6rrlkzrHsI2Dqmq83Z96x7Y/jlVddGitr+dOs+sqmM769yZ+X9Y/8/8fXrhw9zWq6rqZ3dV27ax/X+7qG3D1oQue5N7xxjHL5lufQjbOCTT6DErUlX7PYS6Fm5+UtKZmUa+2ZM8I8kj5+/Tm3d3Y3ZC6NJG6LJXq2nc3VdX1TXzmJ7/dC4/uKo+UFUfn8fv3DTC1QVJnjyfgb26qk6uecze+X0XVdU58/ytVfXKqvpIkh+rqidX1fuq6tqq+r9V9dSdtO3SqnpNTeMp31JVP1jTeKU3VdWlS9a7q6r+y9zWD1TVEXP58VV11bxf76zN45j+cVX9alV9OMm/SfIjSV4979OTq+qlc398oqreXlUHLWnPhVX10bk9L1jShlfM/fSJqrpgLtvp/tY01uq75jZeVVVPq6rHJ/n9JMdvatOS9dfMbTt5Xv61qvqVef75NY0J/JG5ne9ZUtXTq+qDNY3P+tJ5/Zq/hzfObX/hTsqPrKor5zbdWFU/MO/ro+ayy3b0/YRdYnc/ncNkWu6U5P5sfqrXO+eyc5P84jx/QKYnMz0p00AAj53LD8/0ZJxKsi5bjhV6cuanXs3LFyU5Z56/Nckrlrz2gSRPmeefmemxgFu38ZwkF83zl2Z6fvSm4eC+nuS4TH/sXpvk+Hm9keSsef6VS95/fZIfnOf/Y5LfmOf/OMlvLanz0iQvWLJ82JL5X07yz5es99a5/mMzDb2ZTA/9/2iSg+blQ1ewv/8jyb+f55+T5Lpt9etW7/neTENc/oMkf5ppDOADM41M86R5nTdm89PIXpVp/NpHzd/Lz2casOBHMw0bt1+S78r0mMcjd1D+rzM/GW9+7THz/F27+9g27TvTpod8w97g3jHG8VuVPS/J05acta3N9Czc25L8alU9O9MQgUdl+gW8Um9OHhgl6vuTvLXqgcFSDljG+989xhhVdUOSvx5j3DBv75OZ/gC4bm7fpkuwv5/kHVW1NskhY4wPz+W/lykwt2jXdvydqvrlTJfSD86Wz1B+1xjjO0n+rKo29ccPJXndGOOeJBljfGUF+3tSppDLGOODVXXY3PbtGmN8sqrekOTdSZ41xvhWVR2f5JYxjU+bTKF77pK3/cEY494k91bVhzKNX3tSkjeOMe7P9FD+Dyf5uzsovybJ79Y0AMm7xhjX7aidsAhCl71dZTqT2+Lh/PMl4iOSfN8Y476aRi06cBvv/3a2/Jhl63Xunr8+ItO4q1uH/s58c/76nSXzm5a39/O3nGez3r2D1y5NcuYY4xNzP5y8jfYkm4daq23Uudz9fajDtR2X5GvZ/IfQtrazo21ub6i47W5rjHHl/EfY6UneUFWvHmO8fhlthV3GZ7rs7f4oyU/PZy+pqu+paRD3tZnG5b2vqk5J8sR5/W8kecyS9/9FkmNrutt2baaRZx5kTGMgf66qfmyup6rq6btoHx6RzaPc/JMkHxljbEzy1ar6gbn8x5N8eFtvzoP36TFJ7pj75Kxl1P+/k/zEks9+D13B/l65qY75c9o7x47Hi05V/eNMD9F/dpILq+qQTIMQHFOb70jf+o7nM6rqwKo6LNMfEdfMdb+wps/1j5i397HtlVfVEzMdE7+daeSvE+Zt37fp+IFFc6bL3u61mS7Tfrym66BfynQ372VJ3l1VGzJdwv1UkowxvlxV/6+qbkzy3jHGz1XVWzJ9fvrZTJ8xbs9ZSV5TVb+Y5JGZPq/9xC7Yh7uTfG9VXZtkYzYHztlJLp7D8JYkL9nO+9+U5Ler6uWZwvvfJbk60x8UN2TLQH6QMcb75su7G6rqW0n+MNMdvcvZ31cleV1VXZ/knmweAm6bqurwTDezPXeM8fma/r3qv48xzq7pX7neV1V35sFD5X0syRVJvjvJL40xvlBV70zyrLlNI9Pn73+1g/Kzk/xcVd2X5K5MQ8slySVJrq+qj49pGElYGKMMwW5WVXeNMQ7e3e3Y3arq4DHGXfMfT7+Z5LNjjP+2u9sFu5LLy8Ce4qVVdV2ST2b6eOB/7ub2wC7nTBcAmjjTBYAmQhcAmghdAGgidAGgidAFgCZCFwCa/H/1SjU4gGN9/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#グラフ化\n",
    "imp_df = pd.DataFrame()\n",
    "imp_df[\"feature\"] = X.columns\n",
    "imp_df[\"importance\"] = best_clf.feature_importances_\n",
    "imp_df = imp_df.sort_values(\"importance\")\n",
    "\n",
    "x = []\n",
    "for i in range(0,4):\n",
    "    x.append(fscore_xgb_1[i][0])\n",
    "y = []\n",
    "for i in range(0,4):\n",
    "    y.append(fscore_xgb_1[i][1])\n",
    "\n",
    "    \n",
    "Columns = [\"f0\",\"f1\",\"f2\",\"f3\"]\n",
    "Feature_dicted = dict(zip(Columns,tr_X.columns))\n",
    "for i,j in Feature_dicted.items():\n",
    "    print(i,j)\n",
    "    \n",
    "# 可視化\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(x, y)\n",
    "plt.xlabel(\"Feature Importance of xgboost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0 DAYS_BIRTH\n",
      "f1 EXT_SOURCE_1\n",
      "f2 EXT_SOURCE_2\n",
      "f3 EXT_SOURCE_3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#グラフ化\n",
    "imp_df = pd.DataFrame()\n",
    "imp_df[\"feature\"] = X.columns\n",
    "imp_df[\"importance\"] = best_clf.feature_importances_\n",
    "imp_df = imp_df.sort_values(\"importance\")\n",
    "\n",
    "np.array(fscore_xgb_1)[:,0]\n",
    "\n",
    "x = []\n",
    "for i in range(0,4):\n",
    "    x.append(fscore_xgb_1[i][0])\n",
    "y = []\n",
    "for i in range(0,4):\n",
    "    y.append(fscore_xgb_1[i][1])\n",
    "\n",
    "    \n",
    "Columns = [\"f0\",\"f1\",\"f2\",\"f3\"]\n",
    "Feature_dicted = dict(zip(Columns,tr_X.columns))\n",
    "for i,j in Feature_dicted.items():\n",
    "    print(i,j)\n",
    "    \n",
    "# 可視化\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(np.array(fscore_xgb_1)[:,0], np.array(fscore_xgb_1)[:,1])\n",
    "plt.xlabel(\"Feature Importance of xgboost\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
